{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This script is designed to search and compile data from the Alaska Regional Data Repository (RDR) for each project to track data management progress. Each project should have a data management plan, project metadata, associated data, protocol(s), and associated product metadata. While the scipt cannot assertain the quality of these items, it can identify what is present and who is responsible.\n",
    "\n",
    "Returns info: RDR folder, DMP, program; subprogram, record types, title, project status, metadata Status, startDate, endDate, RDR identifier (if present), lastUpdate date, # records publisehd to SB, Point of Contact, owner/trustee, admininstrator, url, if project metadata is Online, Number of products online, # of dictionarys included in metadata, where data is present, how much in raw data and in final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "def find_program(x):\n",
    "    if 'mbm' in x:\n",
    "        y = 'mbm'\n",
    "    elif 'fes' in x:\n",
    "        y = 'fes'\n",
    "    elif 'nwrs' in x:\n",
    "        y = 'nwrs'\n",
    "    elif 'sa' in x:\n",
    "        y = 'sa'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "#define functions\n",
    "def find_team(x):\n",
    "    if 'mbmjv' in x:\n",
    "        y = 'SeaduckJV'\n",
    "    elif 'mbmlb' in x:\n",
    "        y = 'Landbirds'\n",
    "    elif 'mbmra' in x:\n",
    "        y = 'Raptors'\n",
    "    elif 'mbmsb' in x:\n",
    "        y = 'Seabirds'\n",
    "    elif 'mbmsh' in x:\n",
    "        y = 'Shorebirds'\n",
    "    elif 'mbmss' in x:\n",
    "        y = 'Science Support'\n",
    "    elif 'mbmwa' in x: \n",
    "        y = 'Waterfowl'\n",
    "    elif 'mbmambcc' in x:\n",
    "        y = 'AMBCC'\n",
    "    elif 'fessaf' in x:\n",
    "        y = 'Southern Alaskan FWCO Fisheries'\n",
    "    elif 'fessae' in x:\n",
    "        y = 'Southern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesnaf' in x:\n",
    "        y = 'Northern Alaskan FWCO Fisheries'\n",
    "    elif 'fesnae' in x:\n",
    "        y = 'Northern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesmmm' in x:\n",
    "        y = 'Marine Mammals Management'\n",
    "    elif 'fesesc' in x: \n",
    "        y = 'Regional Ecological Services'\n",
    "    elif 'fesisp' in x:\n",
    "        y = 'Invasive Species Program'\n",
    "    elif 'feshrp' in x:\n",
    "        y = 'Habitat Restoration and Partnerships'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "def removeComma(string): #define remove comma function\n",
    "    return string.replace(\",\",\"; \")\n",
    "    \n",
    "def listToString(s): #define converting list to a string format\n",
    "    str1 = \"; \"\n",
    "    return (str1.join(s))\n",
    "    \n",
    "def def_value():\n",
    "    return \"none\"\n",
    "\n",
    "def get_folder_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metavalues(m, contact_md):\n",
    "    import collections\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    \n",
    "    def removeComma(string): #define remove comma function\n",
    "        return string.replace(\",\",\"; \")\n",
    "    \n",
    "    def listToString(s): #define converting list to a string format\n",
    "        str1 = \"; \"\n",
    "        return (str1.join(s))\n",
    "    \n",
    "    #set varibles to defaults \n",
    "    records = \"no metadata\"\n",
    "    title = \"no metadata\"\n",
    "    status = \"no metadata\"\n",
    "    metadataStatus = \"no metadata\"\n",
    "    startDate = 1900\n",
    "    endDate = 1900\n",
    "    DOI = \"none\"\n",
    "    RDR = \"none\"\n",
    "    dateType = \"none\"\n",
    "    lastUpdate = 1900\n",
    "    SB = 0\n",
    "    projectOnline = 0\n",
    "    productsOnline = 0\n",
    "    dictionary = 0\n",
    "    PointOC = \"none\"\n",
    "    owner = \"none\"\n",
    "    admin = \"none\"\n",
    "    url = \"none\"\n",
    "    typeDic = defaultdict(int)  #empty default dictionary to track metadata record types\n",
    "    ids = []\n",
    "    \n",
    "    df = pd.read_json(m)  #read JSON metadata files into dataframe\n",
    "    if len(df.get('data')) == 0 :\n",
    "        print (\"cannot read 'data'\")\n",
    "    else:\n",
    "        values = df.get('data')  #assigns metadata to values\n",
    "        for e in range(0, len(values)):  #json file may have multiple metadata records\n",
    "            element = values[e]  #assign list value e containing the metadata #keys= id, attributes, type\n",
    "            attribute = element.get('attributes')  #keys= profile, json, data-updated\n",
    "            typpe = element.get('type')   #get metadata type\n",
    "            typeDic[typpe] += 1\n",
    "            if typpe != 'records':  #skip if metadata is not a record and is a data dictionary, setting, schemas, custom-profiles...   \n",
    "                continue  #go to next record\n",
    "            jsondata = attribute.get('json')  #create'json' data value\n",
    "            #convert string to dictionary\n",
    "            jsondatadict = json.loads(jsondata)  #3 keys = schema, metadata, mdDictionary\n",
    "            metadata = jsondatadict.get('metadata')  #4 keys = metadataInfo, resourceInfo, associatedResource, resourceDistribution\\n\",\n",
    "            mdDictionary = jsondatadict.get('mdDictionary')\n",
    "            #get metadata key entries\n",
    "            resourceInfo = metadata.get('resourceInfo')        \n",
    "            #resourceInfo = 12 keys: 'resourceType', 'citation', 'pointOfContact', 'abstract', 'shortAbstract', 'status', \\n\",\n",
    "            #...'defaultResourceLocale', 'extent', 'keyword', 'purpose', 'taxonomy', 'timePeriod'\\n\",\n",
    "            resourceType = resourceInfo.get('resourceType')\n",
    "            #parse resource type info\n",
    "            typelist = resourceType[0]\n",
    "            typee = typelist.get('type')\n",
    "            #print ('typee is ', typee)\n",
    "            typeDic[typee] += 1 # count resource type ie project, tabular dataset, dictionary, etc.\n",
    "            typeename = typelist.get('name')\n",
    "            if typeename != None: \n",
    "                typeename = removeComma(typelist.get('name'))  #harvest\n",
    "            citation = resourceInfo.get('citation')\n",
    "            pointOfContact = resourceInfo.get('pointOfContact') #harvested\n",
    "            #gather identifiers to determine repository status\n",
    "            #pull citation identifiers\n",
    "            if 'identifier' in citation:\n",
    "                identify = citation.get('identifier')\n",
    "                for fier in identify:\n",
    "                    #print (fier)\n",
    "                    try:\n",
    "                        ns = fier.get('namespace')\n",
    "                        i = fier.get('identifier')\n",
    "                        nsi = str(ns +': '+i)\n",
    "                        if ns == 'Alaska Regional Data Repository':\n",
    "                            RDR = i  #Harvest\n",
    "                        if ns == 'gov.sciencebase.catalog':\n",
    "                            url = str('https://www.sciencebase.gov/catalog/item/'+ i) #Harvest\n",
    "                            if typee == 'project':\n",
    "                                projectOnline += 1\n",
    "                        ids.append(nsi)  #Harvest\n",
    "                    except:\n",
    "                        continue\n",
    "            if 'gov.sciencebase.catalog' in listToString(ids):\n",
    "                SB += 1\n",
    "            \n",
    "            #Pull metadata from project metadata only\n",
    "            if typee != 'project':\n",
    "                continue\n",
    "            #for project metadata, do following:    \n",
    "            metadataInfo = metadata.get('metadataInfo') #6 Keys = metadataIdentifier, metadataContact, defaultMetadataLocale, metadataDate, parentMetadata, metadataStatus\n",
    "            metadataDate = metadataInfo.get('metadataDate')\n",
    "            #parentMetadata = metadataInfo.get('parentMetadata')\n",
    "            metadataStatus = metadataInfo.get('metadataStatus')  #Harvested\n",
    "            #abstract = removeComma(resourceInfo.get('abstract'))  #harvested\n",
    "            title = removeComma(citation.get('title'))  #harvested\n",
    "            responsibleParty = citation.get('responsibleParty')\n",
    "            statusList = resourceInfo.get('status')\n",
    "            status = statusList[0]  #harvest\n",
    "            #get last update date\n",
    "            try:\n",
    "                for d in range(1, len(metadataDate)):\n",
    "                    metadate = metadataDate[d]\n",
    "                    if metadate.get('dateType') == \"lastUpdate\":\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]\n",
    "                        #dateType = 'last updated'\n",
    "                    else: \n",
    "                        #dateType = metadate.get('dateType')\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]                   \n",
    "            except:\n",
    "                lastUpdate = \"None\"\n",
    "                #dateType = \"None\"\n",
    "            #Get and format startDate and endDate\n",
    "            timePeriod = resourceInfo.get('timePeriod') \n",
    "            try:\n",
    "                startDate = (timePeriod.get('startDateTime','None')).split('T')[0]\n",
    "                end = timePeriod.get('endDateTime', 'None')\n",
    "                if end == None:\n",
    "                    endDate = 'onGoing'\n",
    "                else:\n",
    "                    endDate = end.split('T')[0]\n",
    "            except:\n",
    "                startDate = 'None'\n",
    "                endDate = 'None'\n",
    "\n",
    "\n",
    "        #POINTS of CONTACT\n",
    "        #read Master Contact JSON metadata file into dataframe\n",
    "        contactmetadata = pd.read_json(contact_md)\n",
    "        contactmd1 = dict(contactmetadata)\n",
    "        contactmd2 = contactmd1.get('data')\n",
    "        POC = collections.defaultdict(list) # create empty dictionary for contacts\n",
    "        POCvalues = []\n",
    "        count = 0\n",
    "        #iterate through master contact metadata\n",
    "        for k in contactmd2:\n",
    "            contactmd3 = contactmd2[count]\n",
    "            contactmd4 = contactmd3.get('attributes')\n",
    "            contactmd5 = contactmd4.get('json')\n",
    "            if contactmd5 is not None:\n",
    "                contactmd6 = json.loads(contactmd5)\n",
    "                contactmd7 = dict(contactmd6)\n",
    "                contactIDmd = contactmd7.get('contactId') #harvest id#\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "            # iterate through contacts from metadata\n",
    "            for j in pointOfContact:\n",
    "                party = j.get('party')\n",
    "                for p in range(0, len(party)):\n",
    "                    partyContact = party[p]\n",
    "                    partyContactID = partyContact.get('contactId') #id to compare in master contact list\n",
    "                    role = j.get('role')\n",
    "    \n",
    "                    #compare master list contact ID with metadata contact ID\n",
    "                    if contactIDmd == partyContactID:\n",
    "                        contactName = contactmd7.get('name')\n",
    "                        POC[role].append(contactName)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "        productsOnline = SB - projectOnline\n",
    "        owner = listToString(POC['owner'])\n",
    "        PointOC = listToString(POC['pointOfContact'])\n",
    "        admin = listToString(POC['administrator'])\n",
    "        dictionary = typeDic.get('dictionaries', 0)\n",
    "        records = str(typeDic).removeprefix(str(\"defaultdict(<class 'int'>, {\")).replace(\"})\",'')\n",
    "    \n",
    "    return [records, title, status, metadataStatus, startDate, endDate, RDR, lastUpdate, SB, PointOC, owner, admin, url, projectOnline, productsOnline, dictionary]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ME for mbm! (and fes need to change RDR location)  \n",
    "\n",
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "# Pathway to directory of interest\n",
    "RDR = '\\\\\\\\ifw7ro-file.fws.doi.net\\\\datamgt\\\\fes'\n",
    "#RDR = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\CatalogCSV'\n",
    "\n",
    "# Pathway to the contacts file you want to use to check against existing vs. new contacts; i.e., master AK contacts file\\n\",\n",
    "contact_md = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\AK-contacts-mdeditor-20250130-110146.json'\n",
    "\n",
    "#create dataframe to hold stats\n",
    "stats = pd.DataFrame(columns=['RDR_folder', 'program','subprogram', 'records', 'title', 'projectStatus', 'metadataStatus', 'startDate', 'endDate', \n",
    "                                  'ID', 'lastDate', 'SB', 'pointOfContact', 'dataTrustee', 'dataAdmin', 'url', 'projectOnline', \n",
    "                                  'productsOnline', 'dictionary', 'finalData', 'rawData', 'dataPresent', 'DMP'])                         \n",
    "     \n",
    "#walk project folders\n",
    "folders = os.listdir(RDR) #list of RDR folders\n",
    "for f in folders:\n",
    "    program = find_program(f[0:6]) # change to :5 for MBM and :6 for Fes\n",
    "    if f.find('fes', 0, 3) != -1:  # read MBM or FES project folders only\n",
    "        team = find_team(f[0:6])\n",
    "        DMP = 0\n",
    "        finalByte = 0\n",
    "        rawByte = 0\n",
    "        #metaread = collections.namedtuple('Metadata',['records', 'title', 'status', 'metadataStatus', 'startDate', 'endDate', 'RDR', 'lastUpdate', 'SB', 'PointOC', 'owner', 'admin', 'url', 'projectOnline', 'productsOnline', 'dictionary'])\n",
    "        metaread = ['noMetadata', 'noMetadata', 'noMetadata', 'noMetadata', 1900, 1900, 'noMetadata', 1900, 0, 'noMetadata', 'noMetadata', 'noMetadata', 'noURL', 0, 0, 0]\n",
    "        f2 = os.path.join(RDR, f)\n",
    "        #print ('Opening folder: ', f2)\n",
    "        \n",
    "        for root, dirs, files in os.walk(str(f2), topdown=True):\n",
    "            #print (root)\n",
    "            if root.endswith('final_data') and 'incoming' not in root: # if data folder, find size\n",
    "                finalByte = get_folder_size(root)\n",
    "                if finalByte > 0:\n",
    "                    dataPresent = 1\n",
    "                else:\n",
    "                    dataPresent = 0\n",
    "            if root.endswith('data\\\\raw_data') and 'incoming' not in root:\n",
    "                rawByte = get_folder_size(root)\n",
    "            \n",
    "            for name in files:\n",
    "                 #check for DMP in folder\n",
    "                if name.startswith(\"AK_DMP\", 0, 6) and name.endswith(('.docx', 'docm')):\n",
    "                    DMP += 1\n",
    "                #get project metadata info from mdEditor JSON file\n",
    "                if 'archive' not in root and 'incoming' not in root and '-init-' not in name and 'mdJSON' not in root and 'mdeditor' in name and 'metadata' in root and name.endswith('.json'):\n",
    "                    jfile = os.path.join(root,name)\n",
    "                    metaread = get_metavalues(jfile, contact_md)\n",
    "                    #print ('Reading: ', jfile)\n",
    "                else:\n",
    "                    continue\n",
    "               \n",
    "        #write values to the dataframe\n",
    "        line =[f, program, team, metaread[0], metaread[1], metaread[2], metaread[3], metaread[4], metaread[5], metaread[6], metaread[7], metaread[8], metaread[9], metaread[10], metaread[11], metaread[12], metaread[13], metaread[14], metaread[15], finalByte/1000000, rawByte/1000000, dataPresent, DMP]    \n",
    "        stats.loc[len(stats.index)] = line\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df to csv\n",
    "outfile = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metrics\\\\statsMBM20250405.csv'\n",
    "stats.to_csv(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
