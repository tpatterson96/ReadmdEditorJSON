{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This script is designed to search and compile data from the Alaska Regional Data Repository (RDR) for each project to track data management progress. Each project should have a data management plan, project metadata, associated data, protocol(s), and associated product metadata. While the scipt cannot assertain the quality of these items, it can identify what is present and who is responsible.\n",
    "\n",
    "Returns info: RDR folder, DMP, program; subprogram, record types, title, project status, metadata Status, startDate, endDate, RDR identifier (if present), lastUpdate date, # records publisehd to SB, Point of Contact, owner/trustee, admininstrator, url, if project metadata is Online, Number of products online, # of dictionarys included in metadata, where data is present, how much in raw data and in final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "def find_program(x):\n",
    "    if 'mbm' in x:\n",
    "        y = 'mbm'\n",
    "    elif 'fes' in x:\n",
    "        y = 'fes'\n",
    "    elif 'nwrs' in x:\n",
    "        y = 'nwrs'\n",
    "    elif 'sa' in x:\n",
    "        y = 'sa'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "#define functions\n",
    "def find_team(x):\n",
    "    if 'mbmjv' in x:\n",
    "        y = 'SeaduckJV'\n",
    "    elif 'mbmlb' in x:\n",
    "        y = 'Landbirds'\n",
    "    elif 'mbmra' in x:\n",
    "        y = 'Raptors'\n",
    "    elif 'mbmsb' in x:\n",
    "        y = 'Seabirds'\n",
    "    elif 'mbmsh' in x:\n",
    "        y = 'Shorebirds'\n",
    "    elif 'mbmss' in x:\n",
    "        y = 'Science Support'\n",
    "    elif 'mbmwa' in x: \n",
    "        y = 'Waterfowl'\n",
    "    elif 'mbmambcc' in x:\n",
    "        y = 'AMBCC'\n",
    "    elif 'fesecs' in x:\n",
    "        y = 'Ecological Services Reional Office'\n",
    "    elif 'fescgl' in x:\n",
    "        y = 'Conservation Genetics Lab'\n",
    "    elif 'fessaf' in x:\n",
    "        y = 'Southern Alaskan FWCO Fisheries'\n",
    "    elif 'fessae' in x:\n",
    "        y = 'Southern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesnaf' in x:\n",
    "        y = 'Northern Alaskan FWCO Fisheries'\n",
    "    elif 'fesnae' in x:\n",
    "        y = 'Northern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesmmm' in x:\n",
    "        y = 'Marine Mammals Management'\n",
    "    elif 'fesesc' in x: \n",
    "        y = 'Regional Ecological Services'\n",
    "    elif 'fesisp' in x:\n",
    "        y = 'Invasive Species Program'\n",
    "    elif 'feshrp' in x:\n",
    "        y = 'Habitat Restoration and Partnerships'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "def removeComma(string): #define remove comma function\n",
    "    return string.replace(\",\",\"; \")\n",
    "    \n",
    "def listToString(s): #define converting list to a string format\n",
    "    str1 = \"; \"\n",
    "    return (str1.join(s))\n",
    "    \n",
    "def def_value():\n",
    "    return \"none\"\n",
    "\n",
    "#def get_folder_size(path):\n",
    " #   total_size = 0\n",
    "  #  for dirpath, dirnames, filenames in os.walk(path):\n",
    "   #     for f in filenames:\n",
    "    #        fp = os.path.join(dirpath, f)\n",
    "     #       if not os.path.islink(fp):\n",
    "      #          total_size += os.path.getsize(fp)\n",
    "    #return total_size\n",
    "\n",
    "def get_folder_size(path): #Calculates the total size of a folder and its contents in bytes.\n",
    "    total_size = 0\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file():\n",
    "                total_size += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total_size += get_folder_size(entry.path)\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing path {path}: {e}\")\n",
    "        return 0\n",
    "    return total_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metavalues(m, contact_md):\n",
    "    import collections\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    \n",
    "    def removeComma(string): #define remove comma function\n",
    "        return string.replace(\",\",\"; \")\n",
    "    \n",
    "    def listToString(s): #define converting list to a string format\n",
    "        str1 = \"; \"\n",
    "        return (str1.join(s))\n",
    "    \n",
    "    #set varibles to defaults \n",
    "    records = \"noMetadata\"\n",
    "    title = \"noMetadata\"\n",
    "    status = \"noMetadata\"\n",
    "    metadataStatus = \"noMetadata\"\n",
    "    startDate = 1900\n",
    "    endDate = 1900\n",
    "    DOI = \"none\"\n",
    "    RDR = \"none\"\n",
    "    dateType = \"none\"\n",
    "    lastUpdate = 1900\n",
    "    SB = 0\n",
    "    projectOnline = 0\n",
    "    productsOnline = 0\n",
    "    dictionary = 0\n",
    "    PointOC = \"none\"\n",
    "    owner = \"none\"\n",
    "    admin = \"none\"\n",
    "    url = \"none\"\n",
    "    typeDic = defaultdict(int)  #empty default dictionary to track metadata record types\n",
    "    ids = []\n",
    "    \n",
    "    df = pd.read_json(m)  #read JSON metadata files into dataframe\n",
    "    if len(df.get('data')) == 0 :\n",
    "        print (\"cannot read 'data'\")\n",
    "    else:\n",
    "        values = df.get('data')  #assigns metadata to values\n",
    "        for e in range(0, len(values)):  #json file may have multiple metadata records\n",
    "            element = values[e]  #assign list value e containing the metadata #keys= id, attributes, type\n",
    "            attribute = element.get('attributes')  #keys= profile, json, data-updated\n",
    "            typpe = element.get('type')   #get metadata type\n",
    "            typeDic[typpe] += 1\n",
    "            if typpe != 'records':  #skip if metadata is not a record and is a data dictionary, setting, schemas, custom-profiles...   \n",
    "                continue  #go to next record\n",
    "            jsondata = attribute.get('json')  #create'json' data value\n",
    "            #convert string to dictionary\n",
    "            jsondatadict = json.loads(jsondata)  #3 keys = schema, metadata, mdDictionary\n",
    "            metadata = jsondatadict.get('metadata')  #4 keys = metadataInfo, resourceInfo, associatedResource, resourceDistribution\\n\",\n",
    "            mdDictionary = jsondatadict.get('mdDictionary')\n",
    "            #get metadata key entries\n",
    "            resourceInfo = metadata.get('resourceInfo')        \n",
    "            #resourceInfo = 12 keys: 'resourceType', 'citation', 'pointOfContact', 'abstract', 'shortAbstract', 'status', \\n\",\n",
    "            #...'defaultResourceLocale', 'extent', 'keyword', 'purpose', 'taxonomy', 'timePeriod'\\n\",\n",
    "            resourceType = resourceInfo.get('resourceType')\n",
    "            #parse resource type info\n",
    "            typelist = resourceType[0]\n",
    "            typee = typelist.get('type')\n",
    "            #print ('typee is ', typee)\n",
    "            typeDic[typee] += 1 # count resource type ie project, tabular dataset, dictionary, etc.\n",
    "            typeename = typelist.get('name')\n",
    "            if typeename != None: \n",
    "                typeename = removeComma(typelist.get('name'))  #harvest\n",
    "            citation = resourceInfo.get('citation')\n",
    "            pointOfContact = resourceInfo.get('pointOfContact') #harvested\n",
    "            #gather identifiers to determine repository status\n",
    "            #pull citation identifiers\n",
    "            if 'identifier' in citation:\n",
    "                identify = citation.get('identifier')\n",
    "                for fier in identify:\n",
    "                    #print (fier)\n",
    "                    try:\n",
    "                        ns = fier.get('namespace')\n",
    "                        i = fier.get('identifier')\n",
    "                        nsi = str(ns +': '+i)\n",
    "                        if ns == 'Alaska Regional Data Repository':\n",
    "                            RDR = i  #Harvest\n",
    "                        if ns == 'ServCat':\n",
    "                            if typee == 'project':\n",
    "                                url = str('https://iris.fws.gov/APPS/ServCat/Reference/Profile/'+ i) #Harvest\n",
    "                                projectOnline =+ 1\n",
    "                        if ns == 'gov.sciencebase.catalog':\n",
    "                            if typee == 'project':\n",
    "                                url = str('https://www.sciencebase.gov/catalog/item/'+ i) #Harvest\n",
    "                                projectOnline =+ 1\n",
    "                        ids.append(nsi)  #Harvest\n",
    "                    except:\n",
    "                        continue\n",
    "            if 'gov.sciencebase.catalog' in listToString(ids):\n",
    "                SB += 1\n",
    "            if 'ServCat' in listToString(ids):\n",
    "                SB += 1\n",
    "            \n",
    "            #Pull metadata from project metadata only\n",
    "            if typee != 'project':\n",
    "                continue\n",
    "            #for project metadata, do following:    \n",
    "            metadataInfo = metadata.get('metadataInfo') #6 Keys = metadataIdentifier, metadataContact, defaultMetadataLocale, metadataDate, parentMetadata, metadataStatus\n",
    "            metadataDate = metadataInfo.get('metadataDate')\n",
    "            #parentMetadata = metadataInfo.get('parentMetadata')\n",
    "            metadataStatus = metadataInfo.get('metadataStatus')  #Harvested\n",
    "            #abstract = removeComma(resourceInfo.get('abstract'))  #harvested\n",
    "            title = removeComma(citation.get('title'))  #harvested\n",
    "            responsibleParty = citation.get('responsibleParty')\n",
    "            statusList = resourceInfo.get('status')\n",
    "            status = statusList[0]  #harvest\n",
    "            #get last update date\n",
    "            try:\n",
    "                for d in range(1, len(metadataDate)):\n",
    "                    metadate = metadataDate[d]\n",
    "                    if metadate.get('dateType') == \"lastUpdate\":\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]\n",
    "                        #dateType = 'last updated'\n",
    "                    else: \n",
    "                        #dateType = metadate.get('dateType')\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]                   \n",
    "            except:\n",
    "                lastUpdate = \"None\"\n",
    "                #dateType = \"None\"\n",
    "            #Get and format startDate and endDate\n",
    "            timePeriod = resourceInfo.get('timePeriod') \n",
    "            try:\n",
    "                startDate = (timePeriod.get('startDateTime','None')).split('T')[0]\n",
    "                end = timePeriod.get('endDateTime', 'None')\n",
    "                if end == None:\n",
    "                    endDate = 'onGoing'\n",
    "                else:\n",
    "                    endDate = end.split('T')[0]\n",
    "            except:\n",
    "                startDate = 'None'\n",
    "                endDate = 'None'\n",
    "\n",
    "\n",
    "        #POINTS of CONTACT\n",
    "        #read Master Contact JSON metadata file into dataframe\n",
    "        contactmetadata = pd.read_json(contact_md)\n",
    "        contactmd1 = dict(contactmetadata)\n",
    "        contactmd2 = contactmd1.get('data')\n",
    "        POC = collections.defaultdict(list) # create empty dictionary for contacts\n",
    "        POCvalues = []\n",
    "        count = 0\n",
    "        #iterate through master contact metadata\n",
    "        for k in contactmd2:\n",
    "            contactmd3 = contactmd2[count]\n",
    "            contactmd4 = contactmd3.get('attributes')\n",
    "            contactmd5 = contactmd4.get('json')\n",
    "            if contactmd5 is not None:\n",
    "                contactmd6 = json.loads(contactmd5)\n",
    "                contactmd7 = dict(contactmd6)\n",
    "                contactIDmd = contactmd7.get('contactId') #harvest id#\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "            # iterate through contacts from metadata\n",
    "            for j in pointOfContact:\n",
    "                party = j.get('party')\n",
    "                for p in range(0, len(party)):\n",
    "                    partyContact = party[p]\n",
    "                    partyContactID = partyContact.get('contactId') #id to compare in master contact list\n",
    "                    role = j.get('role')\n",
    "    \n",
    "                    #compare master list contact ID with metadata contact ID\n",
    "                    if contactIDmd == partyContactID:\n",
    "                        contactName = contactmd7.get('name')\n",
    "                        POC[role].append(contactName)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "        productsOnline = SB - projectOnline\n",
    "        owner = listToString(POC['owner'])\n",
    "        PointOC = listToString(POC['pointOfContact'])\n",
    "        admin = listToString(POC['administrator'])\n",
    "        dictionary = typeDic.get('dictionaries', 0)\n",
    "        records = str(typeDic).removeprefix(str(\"defaultdict(<class 'int'>, {\")).replace(\"})\",'')\n",
    "    \n",
    "    return [records, title, status, metadataStatus, startDate, endDate, RDR, lastUpdate, SB, PointOC, owner, admin, url, projectOnline, productsOnline, dictionary]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fescgl_001_MixedStockAnalysis\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fescgl_001_MixedStockAnalysis\\metadata\\mdEditor\\fescgl_001_MixedStockAnalysis-mdeditor-20250411-130453.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fescgl_002_eDNA_SalmonRiver\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fescgl_002_eDNA_SalmonRiver\\metadata\\mdEditor\\fescgl_002_eDNA_SalmonRiver-mdeditor-20250124-140193.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fescgl_003_GeneticSampleInventory_Database\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_001_Oil_Spill_Preparedness_Mapping\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_001_Oil_Spill_Preparedness_Mapping\\metadata\\mdEditor\\fesecs_001_Oil_Spill_Preparedness_Mapping-mdeditor-20250124-150190.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_002_Western_Mariner_NRDAR\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_002_Western_Mariner_NRDAR\\metadata\\mdEditor\\fesecs_002_Western_Mariner_NRDAR-mdeditor-20250124-160130.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_003_NWI_Mapping_Project\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesecs_003_NWI_Mapping_Project\\metadata\\mdEditor\\fesecs_003_NWI_Mapping_Project-mdeditor-20250127-100165.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_001_Fish_BarrierHunter_Alaska\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_001_Fish_BarrierHunter_Alaska\\metadata\\mdEditor\\fessah_001_Fish_BarrierHunter_Alaska-mdeditor-20240917-120985.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_002_CrippleCreek_Occupancy\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_002_CrippleCreek_Occupancy\\metadata\\mdEditor\\feshrp_002_CrippleCreek_Occupancy-mdeditor-20250417-100480.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_003_Chena_SideScanSonar\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\feshrp_003_Chena_SideScanSonar\\metadata\\mdEditor\\feshrp_003_Chena_SideScanSonar-mdeditor-20250203-130213.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_001_Invasive_Inventory_NorthernRefuges\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_001_Invasive_Inventory_NorthernRefuges\\metadata\\mdEditor\\fesisp_001_Invasive_Inventory_NorthernRefuges-mdeditor-20250623-120683.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_002_AquaInvPlants_Survey_Anchorage\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_002_AquaInvPlants_Survey_Anchorage\\metadata\\mdEditor\\fesisp_002_AquaInvPlants_Survey_Anchorage-mdeditor-20250414-120457.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_003_AquaticInvasives_AlcanPOE\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_003_AquaticInvasives_AlcanPOE\\metadata\\mdEditor\\fesisp_003_AquaticInvasives_AlcanPOE-mdeditor-20250207-160287.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_004_invasive_inventory_islands\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_004_invasive_inventory_islands\\metadata\\mdEditor\\fesisp_004_invasive_inventory_islands-mdeditor-20250401-170482.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesisp_005_blackslug_inventory_islands\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_001_SeasonalDist_SeaOtters\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_001_SeasonalDist_SeaOtters\\metadata\\mdEditor\\fesmmm_001_SeasonalDist_SeaOtters-mdeditor-20250407-150443.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_002_SeaOtter_Population_WestAleutians\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_002_SeaOtter_Population_WestAleutians\\metadata\\mdEditor\\fesmmm_002_SeaOtter_Population_WestAleutians-mdeditor-20250407-150447.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_003_SeaOtter_SoutheastSurvey\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_003_SeaOtter_SoutheastSurvey\\metadata\\mdEditor\\fesmmm_003_SeaOtter_SoutheastSurvey-mdeditor-20250407-150464.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_004_Walrus_HauloutMortality\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_004_Walrus_HauloutMortality\\metadata\\mdEditor\\fesmmm_004_Walrus_HauloutMortality-mdeditor-20250407-160415.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_005_Walrus_HarvestMonitoring\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_005_Walrus_HarvestMonitoring\\metadata\\mdEditor\\fesmmm_005_Walrus_HarvestMonitoring-mdeditor-20250407-160483.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_006_Walrus_CameraMonitoring\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_006_Walrus_CameraMonitoring\\metadata\\mdEditor\\fesmmm_006_Walrus_CameraMonitoring-mdeditor-20250407-160401.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_007_MarineMammal_MTRP\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_007_MarineMammal_MTRP\\metadata\\mdEditor\\fesmmm_007_MarineMammal_MTRP-mdeditor-20250408-090420.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_008_LHX_TagPilot\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_008_LHX_TagPilot\\metadata\\mdEditor\\fesmmm_008_LHX_TagPilot-mdeditor-20250408-090494.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_009_PolarBearIndustryConflict\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_009_PolarBearIndustryConflict\\metadata\\mdEditor\\fesmmm_009_PolarBearIndustryConflict-mdeditor-20250408-090444.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_010_PolarBear_LOADB\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_011_PB_Safety_Training_Database\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_012_Walrus_PB_Conservation_Chukotka\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_012_Walrus_PB_Conservation_Chukotka\\metadata\\mdEditor\\fesmmm_012_Walrus_PB_Conservation_Chukotka-mdeditor-20250408-100438.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_013_PolarBear_Aircraft_Behavior\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_013_PolarBear_Aircraft_Behavior\\metadata\\mdEditor\\fesmmm_013_PolarBear_Aircraft_Behavior-mdeditor-20250408-100496.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_014_PB_AerialEstimates_SBS\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_014_PB_AerialEstimates_SBS\\metadata\\mdEditor\\fesmmm_014_PB_AerialEstimates_SBS-mdeditor-20250408-100458.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_016_PB_Captures_Kotzebue\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_016_PB_Captures_Kotzebue\\metadata\\mdEditor\\fesmmm_016_PB_Captures_Kotzebue-mdeditor-20250408-100491.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_017_walrus_mortalityDB_BeringChukchi\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_017_walrus_mortalityDB_BeringChukchi\\metadata\\mdEditor\\fesmmm_017_walrus_mortalityDB_BeringChukchi-mdeditor-20250915-100991.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_019_PB_TerrestrialForaging_HudsonBay\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_019_PB_TerrestrialForaging_HudsonBay\\metadata\\mdEditor\\fesmmm_019_PB_TerrestrialForaging_HudsonBay-mdeditor-20240806-110802.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_021_Wrangel_Island\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_021_Wrangel_Island\\metadata\\mdEditor\\fesmmm_021_Wrangel_Island-mdeditor-20250408-100459.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_022_Walrus_Geofence_Expansion_Project\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_022_Walrus_Geofence_Expansion_Project\\metadata\\mdEditor\\fesmmm_022_Walrus_Geofence_Expansion_Project-mdeditor-20250408-100484.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_023_PolarBear_MassValidation\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_023_PolarBear_MassValidation\\metadata\\mdEditor\\fesmmm_023_PolarBear_MassValidation-mdeditor-20250916-080935.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_024_PB_Geospatial_HumanConflict_NorthSlope\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_024_PB_Geospatial_HumanConflict_NorthSlope\\metadata\\mdEditor\\fesmmm_024_PB_Geospatial_HumanConflict_NorthSlope-mdeditor-20250408-110415.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_025_PB_ChukchiSea_Monitoring\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_025_PB_ChukchiSea_Monitoring\\metadata\\mdEditor\\fesmmm_025_PB_ChukchiSea_Monitoring-mdeditor-20250408-110404.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_026_Walrus_CloseKinMR\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_026_Walrus_CloseKinMR\\metadata\\mdEditor\\fesmmm_026_Walrus_CloseKinMR-mdeditor-20250408-110448.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesmmm_027_ANWR_Oil_Spill_Simulations\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_001_RTLO_PALO_ArcticNWR\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_001_RTLO_PALO_ArcticNWR\\metadata\\mdEditor\\fesnae_001_RTLO_PALO_ArcticNWR-mdeditor-20250115-080109.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_002_s7_spatial_db_nafwfo\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_002_s7_spatial_db_nafwfo\\metadata\\mdEditor\\fesnae_002_s7_spatial_db_nafwfo-mdeditor-20250115-090126.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_003_Midazolam_SPEI\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_003_Midazolam_SPEI\\metadata\\mdEditor\\fesnae_003_Midazolam_SPEI-mdeditor-20250228-160288.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_004_WinterDist_SPEI\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_004_WinterDist_SPEI\\metadata\\mdEditor\\fesnae_004_WinterDist_SPEI-mdeditor-20250226-140296.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_005_SPEI_PTT_Deployment\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_005_SPEI_PTT_Deployment\\metadata\\mdEditor\\fesnae_005_SPEI_PTT_Deployment-mdeditor-20250404-120477.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_006_Eider_Breeding_Utqiagvik\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_006_Eider_Breeding_Utqiagvik\\metadata\\mdEditor\\fesnae_006_Eider_Breeding_Utqiagvik-mdeditor-20250226-160291.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_007_STEI_AerialSurvey_Utqiagvik\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_007_STEI_AerialSurvey_Utqiagvik\\metadata\\mdEditor\\fesnae_007_STEI_AerialSurvey_Utqiagvik-mdeditor-20250522-140507.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_008_SPEI_Assessment_Foraging_Behavior\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_008_SPEI_Assessment_Foraging_Behavior\\metadata\\mdEditor\\fesnae_008_SPEI_Assessment_Foraging_Behavior-mdeditor-20250227-120254.json\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_008_SPEI_Assessment_Foraging_Behavior\\metadata\\mdEditor\\fesnae_008_SPEI_Assessment_Foraging_Behavior-mdeditor-20250303-100399.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_009_SPEI_Global_Abundance\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_009_SPEI_Global_Abundance\\metadata\\mdEditor\\fesfrp_008_SPEI_Global_Abundance_mdeditor-20220409.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_010_SPEI_Survival_Kigigak\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_010_SPEI_Survival_Kigigak\\metadata\\mdEditor\\fesnae_010_SPEI_Survival_Kigigak-mdeditor-20250318-150351.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_011_SPEI_Reprod_Analysis_Kigigak\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_011_SPEI_Reprod_Analysis_Kigigak\\metadata\\mdEditor\\fesnae_011_SPEI_Reprod_Analysis_Kigigak-mdeditor-20250325-100381.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_012_STEI_Historical_Dataset\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_012_STEI_Historical_Dataset\\metadata\\mdEditor\\fesnae_012_STEI_Historical_Dataset-mdeditor-20250424-140404.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_013_SPEI_BloodLead\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_013_SPEI_BloodLead\\metadata\\mdEditor\\fesnae_013_SPEI_BloodLead-mdeditor-20250404-120464.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_014_SPEI_Harvest_Russia\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_014_SPEI_Harvest_Russia\\metadata\\mdEditor\\fesnae_014_SPEI_Harvest_Russia-mdeditor-20250408-120461.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_015_SPEI_imageProc_WinterSurvey\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_015_SPEI_imageProc_WinterSurvey\\metadata\\mdEditor\\fesnae_015_SPEI_imageProc_WinterSurvey-mdeditor-20250602-160645.json\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnae_015_SPEI_imageProc_WinterSurvey\\metadata\\mdEditor\\fesnae_015_SPEI_imageProc_WinterSurvey-mdeditor-20250707-090722.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_001_SheefishSpawning_SalmonFork\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_001_SheefishSpawning_SalmonFork\\metadata\\mdEditor\\fesnaf_001_SheefishSpawning_SalmonFork-mdeditor-20250922-160994.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_002_GisasaWeir\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_002_GisasaWeir\\metadata\\mdEditor\\fesnaf_002_GisasaWeir-mdeditor-20250415-150419.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_003_Chinook_EmigrationTiming\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_003_Chinook_EmigrationTiming\\metadata\\mdEditor\\fesnaf_003_Chinook_EmigrationTiming-mdeditor-20240822-130808.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_004_ChenaRiver_Chinook\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_004_ChenaRiver_Chinook\\metadata\\mdEditor\\fesnaf_004_ChenaRiver_Chinook-mdeditor-20250922-130918.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_005_AndreafskyWeir\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_005_AndreafskyWeir\\metadata\\mdEditor\\fesnaf_005_AndreafskyWeir-mdeditor-20250404-080443.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_006_ChandalarWeir\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_006_ChandalarWeir\\metadata\\mdEditor\\fesnaf_006_ChandalarWeir-mdeditor-20250226-080294.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_011_HumpbackWhitefish_Tanana\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_011_HumpbackWhitefish_Tanana\\metadata\\mdEditor\\fesnaf_011_HumpbackWhitefish_Tanana-mdeditor-20240823-090878.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_013_Chinook_Ichthyophonus_Yukon\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_013_Chinook_Ichthyophonus_Yukon\\metadata\\mdEditor\\fesnaf_013_Chinook_Ichthyophonus_Yukon-mdeditor-20250905-090904.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_014_SQT_ACP\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_016_Inconnu_SelawikRiver_AgeStructure\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_016_Inconnu_SelawikRiver_AgeStructure\\metadata\\mdEditor\\fesnaf_016_Inconnu_SelawikRiver_AgeStructure-mdeditor-20250211-110297.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_017_Inconnu_YukonRiver_ASL\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_017_Inconnu_YukonRiver_ASL\\metadata\\mdEditor\\fesnaf_017_Inconnu_YukonRiver_ASL-mdeditor-20250818-140868.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_018_BeringCisco_LifeHistory_YukonRiver\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fesnaf_018_BeringCisco_LifeHistory_YukonRiver\\metadata\\mdEditor\\fesnaf_018_BeringCisco_LifeHistory_YukonRiver-mdeditor-20250729-140779.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_001_Mariculture_TrustResources_Interactions\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_001_Mariculture_TrustResources_Interactions\\metadata\\mdEditor\\fessae_001_Mariculture_TrustResources_Interactions-mdeditor-20250211-100297.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_002_CameraMethods_WolvesPrey\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_002_CameraMethods_WolvesPrey\\metadata\\mdEditor\\fessae_002_CameraMethods_WolvesPrey-mdeditor-20250211-100220.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_003_STAL_Senkaku_Imagery\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_003_STAL_Senkaku_Imagery\\metadata\\mdEditor\\fessae_003_STAL_Senkaku_Imagery-mdeditor-20250211-090214.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_004_TUPU_Genetics_North_Pacific\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_004_TUPU_Genetics_North_Pacific\\metadata\\mdEditor\\fessae_004_TUPU_Genetics_North_Pacific-mdeditor-20250211-090250.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_005_Southeast_Alaska_GIS\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_005_Southeast_Alaska_GIS\\metadata\\mdEditor\\fessae_005_Southeast_Alaska_GIS-mdeditor-20250211-080218.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_006_ChilkatWatershed_WQ_Temperature\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_006_ChilkatWatershed_WQ_Temperature\\metadata\\mdEditor\\fessae_006_ChilkatWatershed_WQ_Temperature-mdeditor-20230323-130341.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_007_STAL_YIO_NestCounts\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_007_STAL_YIO_NestCounts\\metadata\\mdEditor\\fessae_007_STAL_YIO_NestCounts-mdeditor-20250210-120245.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_011_BattleCreekEstuary_Water_Diversion\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_011_BattleCreekEstuary_Water_Diversion\\metadata\\mdEditor\\fessae_011_BattleCreekEstuary_Water_Diversion-mdeditor-20250210-100216.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_017_AAWolf_Genetics\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_017_AAWolf_Genetics\\metadata\\mdEditor\\fessae_017_AAWolf_Genetics-mdeditor-20250210-100252.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_022_AK_STAL_Vessel_Threats\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_022_AK_STAL_Vessel_Threats\\metadata\\mdEditor\\fessae_022_AK_STAL_Vessel_Threats-mdeditor-20250210-100245.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_024_butterfly_monitoring_alaska\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessae_024_butterfly_monitoring_alaska\\metadata\\mdEditor\\fessae_024_butterfly_monitoring_alaska-mdeditor-20250826-100879.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_001_ChinookSalmon_JuvSamp_DeshkaRiver\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_001_ChinookSalmon_JuvSamp_DeshkaRiver\\metadata\\mdEditor\\fessaf_001_ChinookSalmon_JuvSamp_DeshkaRiver-mdeditor-20250904-170919.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_003_Area1002_WaterAvailability\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_003_Area1002_WaterAvailability\\metadata\\mdEditor\\fessaf_003_Area1002_WaterAvailability-mdeditor-20230718-150729.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_003_CohoSalmon_Kenai_StockDiversity\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_003_CohoSalmon_Kenai_StockDiversity\\metadata\\mdEditor\\feskcof_001_CohoSalmon_Kenai_StockDiversity_mdeditor-20220409.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_004_Juvenile_Salmon_Trapping\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_004_Juvenile_Salmon_Trapping\\metadata\\mdEditor\\fessaf_004_Juvenile_Salmon_Trapping-mdeditor-20250819-140899.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_006_Chignik_Juvenile_Chinook\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_007_ChinookSalmon_Tibit_JBER\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_007_ChinookSalmon_Tibit_JBER\\metadata\\mdEditor\\fessaf_007_ChinookSalmon_Tibit_JBER-mdeditor-20250715-100715.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_009_Salmon_SpawnerTelemetry_Deshka\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_009_Salmon_SpawnerTelemetry_Deshka\\metadata\\mdEditor\\fessaf_009_Salmon_SpawnerTelemetry_Deshka-mdeditor-20250610-130641.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_010_GulkanaRiver_ThermalMapping\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_010_GulkanaRiver_ThermalMapping\\metadata\\mdEditor\\fessaf_010_GulkanaRiver_ThermalMapping-mdeditor-20250710-140771.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_011_Salmon_TogiakRiver\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_011_Salmon_TogiakRiver\\metadata\\mdEditor\\fessaf_011_Salmon_TogiakRiver-mdeditor-20250924-080960.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_012_Aniakchak_Fisheries\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_012_Aniakchak_Fisheries\\metadata\\mdEditor\\fessaf_012_Aniakchak_Fisheries-mdeditor-20250924-080963.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_013_RainbowTrout_TogiakNWR\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_013_RainbowTrout_TogiakNWR\\metadata\\mdEditor\\fessaf_013_RainbowTrout_TogiakNWR-mdeditor-20230509-090583.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_016_SalmonHabitat_BigLake\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_016_SalmonHabitat_BigLake\\metadata\\mdEditor\\fessaf_016_SalmonHabitat_BigLake-mdeditor-20250207-150216.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_017_DeshkaRiver_SalmonTempSSP\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_017_DeshkaRiver_SalmonTempSSP\\metadata\\mdEditor\\fessaf_017_DeshkaRiver_SalmonTempSSP-mdeditor-20250729-100719.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_018_NorthernPike_Predation_JBER\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_018_NorthernPike_Predation_JBER\\metadata\\mdEditor\\fessaf_018_NorthernPike_Predation_JBER-mdeditor-20250606-120604.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_019_Salmon_Overwinter_JBER\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_019_Salmon_Overwinter_JBER\\metadata\\mdEditor\\fessaf_019_Salmon_Overwinter_JBER-mdeditor-20250625-080656.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_020_Salmon_SpawningHabitat_JBER\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_020_Salmon_SpawningHabitat_JBER\\metadata\\mdEditor\\fessaf_020_Salmon_SpawningHabitat_JBER-mdeditor-20250708-110747.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_021_Salmon_Weir_JBER\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_021_Salmon_Weir_JBER\\metadata\\mdEditor\\fessaf_021_Salmon_Weir_JBER-mdeditor-20250610-130663.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_022_Kenai_Coho_AdultTelemetry\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_022_Kenai_Coho_AdultTelemetry\\metadata\\mdEditor\\fessaf_022_Kenai_Coho_AdultTelemetry-mdeditor-20250203-160219.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_023_whitefish_MR_KuskakwimRiver\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_024_Kwethluk_SalmonRunTiming\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_024_Kwethluk_SalmonRunTiming\\metadata\\mdEditor\\fessaf_024_Kwethluk_SalmonRunTiming-mdeditor-20250902-160915.json\n",
      "Opening folder:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_025_Salmon_BeadedStreamTemp_CookInlet\n",
      "Reading:  \\\\ifw7ro-file.fws.doi.net\\datamgt\\fes\\fessaf_025_Salmon_BeadedStreamTemp_CookInlet\\metadata\\mdEditor\\fessaf_025_Salmon_BeadedStreamTemp_CookInlet-mdeditor-20250819-110881.json\n"
     ]
    }
   ],
   "source": [
    "#RUN ME for mbm! (and fes need to change RDR location)  \n",
    "\n",
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "# Pathway to directory of interest\n",
    "#RDR = \"W:\\\\fes\\\\\"\n",
    "RDR = '\\\\\\\\ifw7ro-file.fws.doi.net\\\\datamgt\\\\fes\\\\'  #change for mbb or fes\n",
    "\n",
    "\n",
    "# Pathway to the contacts file you want to use to check against existing vs. new contacts; i.e., master AK contacts file\\n\",\n",
    "contact_md = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\AK_contacts_profiles\\\\AK-contacts-mdeditor-20250818-205544.json'\n",
    "\n",
    "#create dataframe to hold stats\n",
    "stats = pd.DataFrame(columns=['RDR_folder', 'program','subprogram', 'records', 'title', 'projectStatus', 'metadataStatus', 'startDate', 'endDate', \n",
    "                                  'ID', 'lastDate', 'SB', 'pointOfContact', 'dataTrustee', 'dataAdmin', 'url', 'projectOnline', \n",
    "                                  'productsOnline', 'dictionary', 'finalData', 'rawData', 'dataPresent', 'DMP'])                         \n",
    "     \n",
    "#walk project folders\n",
    "folders = os.listdir(RDR) #list of RDR folders\n",
    "for f in folders:\n",
    "    program = find_program(f[0:3]) # find program name\n",
    "    if f.find('fes', 0, 3) != -1:  # read MBM or FES project folders only\n",
    "        team = find_team(f[0:6])    # change to :5 for MBM and :6 for Fes\n",
    "        DMP = 0\n",
    "        finalByte = 0\n",
    "        rawByte = 0\n",
    "        dataPresent = 0\n",
    "        #metaread = collections.namedtuple('Metadata',['records', 'title', 'status', 'metadataStatus', 'startDate', 'endDate', 'RDR', 'lastUpdate', 'SB', 'PointOC', 'owner', 'admin', 'url', 'projectOnline', 'productsOnline', 'dictionary'])\n",
    "        metaread = ['noMetadata', 'noMetadata', 'noMetadata', 'noMetadata', 1900, 1900, 'noMetadata', 1900, 0, 'noMetadata', 'noMetadata', 'noMetadata', 'noURL', 0, 0, 0] #set defaults\n",
    "        f2 = os.path.join(RDR, f)\n",
    "        print ('Opening folder: ', f2)\n",
    "        \n",
    "        for root, dirs, files in os.walk(str(f2), topdown=True):\n",
    "            #print (root)\n",
    "            if root.endswith('final_data') and 'incoming' not in root: # if data folder, find size\n",
    "                finalByte = get_folder_size(root)\n",
    "                if finalByte > 0:\n",
    "                    dataPresent = 1\n",
    "                else:\n",
    "                    dataPresent = 0\n",
    "            if root.endswith('data\\\\raw_data') and 'incoming' not in root:\n",
    "                rawByte = get_folder_size(root)\n",
    "                if rawByte >0:\n",
    "                    dataPresent = 1\n",
    "            \n",
    "            for name in files:\n",
    "                 #check for DMP in folder\n",
    "                if name.startswith(\"AK_DMP\", 0, 6) and name.endswith(('.docx', 'docm')):\n",
    "                    DMP += 1\n",
    "                #if name.endswith(('.docx', 'docm')): #check for other documents\n",
    "                    #print (f'Project folder {f2} \\n contains document {name} \\n')\n",
    "                #get project metadata info from mdEditor JSON file\n",
    "                if 'archive' not in root and 'incoming' not in root and '-init-' not in name and 'mdeditor' in name and 'mdJSON' not in root and 'metadata' in root and name.endswith('.json'):\n",
    "                    jfile = os.path.join(root,name)\n",
    "                    metaread = get_metavalues(jfile, contact_md)\n",
    "                    print ('Reading: ', jfile)\n",
    "                else:\n",
    "                    continue\n",
    "               \n",
    "        #write values to the dataframe\n",
    "        line =[f, program, team, metaread[0], metaread[1], metaread[2], metaread[3], metaread[4], metaread[5], metaread[6], metaread[7], metaread[8], metaread[9], metaread[10], metaread[11], metaread[12], metaread[13], metaread[14], metaread[15], finalByte/1000000, rawByte/1000000, dataPresent, DMP]    \n",
    "        stats.loc[len(stats.index)] = line\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df to csv\n",
    "outfile = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metrics\\\\statsfes20251121.csv'\n",
    "stats.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for single test JSON\n",
    "\n",
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "# Pathway to directory of interest\n",
    "m = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\RDRstats\\\\fesnaf_005_AndreafskyWeir-mdeditor-20250404-080443.json'\n",
    "\n",
    "\n",
    "# Pathway to the contacts file you want to use to check against existing vs. new contacts; i.e., master AK contacts file\\n\",\n",
    "contact_md = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\AK-contacts-mdeditor-20250130-110146.json'\n",
    "\n",
    "meta = get_metavalues(m, contact_md)\n",
    "\n",
    "print (len(meta))\n",
    "for item in meta:\n",
    "    print (item)\n",
    "\n",
    "#return [records, title, status, metadataStatus, startDate, endDate, RDR, lastUpdate, SB, PointOC, owner, admin, url, projectOnline, productsOnline, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (records)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
