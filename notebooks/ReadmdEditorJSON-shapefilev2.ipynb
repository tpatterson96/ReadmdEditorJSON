{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to read mdEditor files, and write out as csv \n",
    "#and shapefile with geography, if applicable\n",
    "#by Tamatha A. Patterson; verson 5; December 2022\n",
    "#distribution section updated.\n",
    "#extent merged with metadata and written to shapefile. #FeatureCollection type handled.\n",
    "#associations section updated.\n",
    "\n",
    "def mdEditor_read(metadataToRead, contact_md, csvname, workspace, resourcetype = True, geo = False):\n",
    "    #recordtype used to write chosen resource types  \\\"all\\\", \\\"project\\\", etc.in future versions\n",
    "    #extent/geography read when is True, skipped when False.\n",
    "    import os\n",
    "    import json\n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import geopandas as gpd\n",
    "    import collections\n",
    "    import fiona\n",
    "    from shapely.geometry import Point, LineString, Polygon, MultiPolygon\n",
    "    from datetime import date\n",
    "    \n",
    "    def removeComma(string): #define remove comma function\n",
    "        return string.replace(\",\",\"; \")\n",
    "    \n",
    "    def listToString(s): #define converting list to a string format\n",
    "        str1 = \"; \"\n",
    "        return (str1.join(s))\n",
    "    \n",
    "    def def_value():\n",
    "        return \"none\"\n",
    "    \n",
    "    os.chdir(workspace) # assign working directory\n",
    "    \n",
    "    df = pd.read_json(metadataToRead)#read JSON metadata files into dataframe\n",
    "    values = df.get('data') #assigns metadata to values\n",
    "    for e in range(0, len(values)): #json file may have multiple metadata records\n",
    "        element = values[e] #assign list value e containing the metadata #keys= id, attributes, type\n",
    "        ID = element.get('id') #get metadata id\n",
    "        attribute = element.get('attributes') # keys= profile, json, data-updated\n",
    "        typpe = element.get('type') #get metadata type\n",
    "        if typpe != 'records':  # skip if metadata is not a record and is a data dictionary, setting, schemas, custom-profiles...\n",
    "            continue  #go to next record \n",
    "            \n",
    "        #parse 'attribute' to create profile, json, and date-updated\\n\",\n",
    "        dateUpdate = attribute.get('date-updated') #create dateUpdate value--where does this date come from???\n",
    "        jsondata = attribute.get('json') #create'json' data value\n",
    "        profile = attribute.get('profile') #create 'profile' value\n",
    "        \n",
    "        #convert string to dictionary\n",
    "        jsondatadict = json.loads(jsondata)  #3 keys = schema, metadata, mdDictionary\n",
    "        schema = jsondatadict.get('schema')\n",
    "        metadata = jsondatadict.get('metadata') #4 keys = metadataInfo, resourceInfo, associatedResource, resourceDistribution\\n\",\n",
    "        mdDictionary = jsondatadict.get('mdDictionary')\n",
    "        #get metadata key entries\n",
    "        metadataInfo = metadata.get('metadataInfo') #6 Keys = metadataIdentifier, metadataContact, defaultMetadataLocale, metadataDate, parentMetadata, metadataStatus\n",
    "        resourceInfo = metadata.get('resourceInfo') #12 keys = resourceType, citation, pointOfContact, abstract, shortAbstract, status, defaultResourceLocale, extent, keyword, purpose, taxonomy, timePeriod\n",
    "        associatedResource = metadata.get('associatedResource') #is list\n",
    "        resourceDistribution = metadata.get('resourceDistribution') #keys = n\n",
    "        \n",
    "        #parse resourceInfo resourceType key of 12: 'resourceType'\n",
    "        resourceType = resourceInfo.get('resourceType')\n",
    "        #parse resource Type info\n",
    "        typelist = resourceType[0]\n",
    "        typee = typelist.get('type')\n",
    "        typeename = typelist.get('name')\n",
    "        if typeename != None: \n",
    "            typeename = removeComma(typelist.get('name'))\n",
    "            \n",
    "        #check if desired resource type is record resource type, go to next record if not.\n",
    "        if any([resourcetype == typee, resourcetype == True]):  \n",
    "            print(f\"Search record resource type is {resourcetype} and record resource type is {typee}.\")\n",
    "        else: \n",
    "            print(f'Not a {resourcetype}, moving on.')\n",
    "            continue\n",
    "            \n",
    "        #parse metadataInfo dictionary 6 keys\n",
    "        metadataIdentifier = metadataInfo.get('metadataIdentifier') #Harvest as ID to fields\n",
    "        metadataContact = metadataInfo.get('metadataContact')\n",
    "        defaultMetadataLocale = metadataInfo.get('defaultMetadataLocale')\n",
    "        metadataDate = metadataInfo.get('metadataDate')\n",
    "        parentMetadata = metadataInfo.get('parentMetadata')\n",
    "        metadataStatus = metadataInfo.get('metadataStatus') #Harvest as status to fields\n",
    "\n",
    "        #get metadata uuid identifier; autocreated in mdEditor\\n\",\n",
    "        if metadataIdentifier['namespace'] == 'urn:uuid':\n",
    "                metaIdentifier = metadataIdentifier.get('identifier')\n",
    "\n",
    "        #parse resourceInfo 11/12 keys: 'resourceType'(above), 'citation', 'pointOfContact', 'abstract', 'shortAbstract', 'status', \\n\",\n",
    "        #...'defaultResourceLocale', 'extent', 'keyword', 'purpose', 'taxonomy', 'timePeriod'\\n\",\n",
    "        citation = resourceInfo.get('citation')\n",
    "        pointOfContact = resourceInfo.get('pointOfContact')\n",
    "        abstract = removeComma(resourceInfo.get('abstract')) #harvested to fields\n",
    "        if resourceInfo.get('shortAbstract') == None:\n",
    "            shortAbstract = \" \"\n",
    "        else:\n",
    "            shortAbstract = removeComma(resourceInfo.get('shortAbstract'))#harvested as shortAbstract to fields\n",
    "        statusList = resourceInfo.get('status')\n",
    "        status = statusList[0]#harvest as status to fields\n",
    "        defaultResourceLocale = resourceInfo.get('defaultResourceLocale')\n",
    "        extent = resourceInfo.get('extent')\n",
    "        keyword = resourceInfo.get('keyword')\n",
    "        if resourceInfo.get('purpose') == None:\n",
    "            purpose = \" \"\n",
    "        else:\n",
    "            purpose = removeComma(resourceInfo.get('purpose')) #harvested to fields\n",
    "        taxonomy = resourceInfo.get('taxonomy')\n",
    "        timePeriod = resourceInfo.get('timePeriod')\n",
    "        \n",
    "        #find last update date from metadataDate\n",
    "        #Consider comparing this to last run date and only reading metadata updated after????\n",
    "        if len(metadataDate) == 1:\n",
    "            lastUpdate = metadataDate[0].get('date') \n",
    "            dateType = metadataDate[0].get('dateType')\n",
    "        else:\n",
    "            if len(metadataDate) > 1:\n",
    "                for i in metadataDate:\n",
    "                    if i.get('dateType') == \"lastUpdate\":\n",
    "                        lastUpdate = (i.get('date')).split('T')[0]\n",
    "                        dateType = 'last updated'\n",
    "                    else: \n",
    "                        dateType = i.get('dateType')\n",
    "                        lastUpdate = (i.get('date')).split('T')[0]                   \n",
    "\n",
    "        #parse citation info\n",
    "        title = removeComma(citation.get('title')) #harvested as title to fields\n",
    "        dates = citation.get('date')\n",
    "        responsibleParty = citation.get('responsibleParty')\n",
    "        altTitle = citation.get('alternateTitle')\n",
    "        if altTitle != None:\n",
    "            altTitle = listToString(altTitle)#Harvested as altTitle to fields\n",
    "            altTitle = removeComma(altTitle)\n",
    "         \n",
    "        #pull citation identifiers (added 10 April 2024)\n",
    "        #print(citation)\n",
    "        ids = []\n",
    "        identify = citation.get('identifier')\n",
    "        #print (identify)\n",
    "        if 'identifier' in citation:\n",
    "            for fier in identify:\n",
    "                ns = fier.get('namespace')\n",
    "                i = fier.get('identifier')\n",
    "                if ns is not None:\n",
    "                    nsi = str(ns +': '+i)\n",
    "                    ids.append(nsi) #Harvested to fields\n",
    "            ids = listToString(ids)\n",
    "        else:\n",
    "            ids = 'none'\n",
    "        #print (ids)\n",
    "        \n",
    "        #Get and format startDate and endDate\n",
    "        try:\n",
    "            startDate = (timePeriod.get('startDateTime','None')).split('T')[0]\n",
    "            end = timePeriod.get('endDateTime', 'None')\n",
    "            if end == None:\n",
    "                endDate = 'onGoing'\n",
    "            else:\n",
    "                endDate = end.split('T')[0]\n",
    "        except:\n",
    "            startDate = 'None'\n",
    "            endDate = 'None'\n",
    "        \n",
    "        #KEYWORDS: create empty list for keywords\n",
    "        klist =[]\n",
    "        #loop through keyword thesaurus and add keywords to keyword list\n",
    "        try:\n",
    "            for g in range(0, len(keyword)):\n",
    "                word = keyword[g]\n",
    "                word1 = word.get('keyword')\n",
    "                for h in range(0, len(word1)):\n",
    "                    word2 = word1[h]\n",
    "                    word3 = word2.get('keyword')\n",
    "                    klist.append(word3)\n",
    "            keywords = listToString(klist)\n",
    "        except:\n",
    "            keywords = 'None'\n",
    "    \n",
    "        #TAXONOMY: parse species names from taxonomy; may need to loop if more than one species. updated 14June2024\n",
    "        if 'taxonomy' not in resourceInfo:# check for taxonomy entry\n",
    "            taxnameList = 'none'\n",
    "            comnameList = 'none'\n",
    "        else:\n",
    "            taxname = []\n",
    "            comname = []\n",
    "            commonname = \"\"\n",
    "            taxdic = taxonomy[0] #list len 1 to dictionary\n",
    "            taxClass = taxdic.get('taxonomicClassification') #list len1\n",
    "            if len(taxClass) == 1:\n",
    "                taxSys = taxdic.get('taxonomicSystem')\n",
    "                if (taxSys[0].get('citation')).get('title')=='Integrated Taxonomic Information System (ITIS)': #if using ITIS taxonomy, continue.\n",
    "                    taxClass1 = taxClass[0]\n",
    "                    taxSysID = taxClass1.get('taxonoicSystemID')\n",
    "                    taxLevel = taxClass1.get('taxonomicLevel')\n",
    "                    taxName = taxClass1.get('taxonomicName')\n",
    "                    taxSubClass = taxClass1.get('subClassification')\n",
    "                    \n",
    "                    for a in range(0, len(taxSubClass)): \n",
    "                        taxSubL = taxSubClass[a]\n",
    "                        \n",
    "                        for b in range (0, len(taxSubL)):\n",
    "                            #taxSysID0 = taxSubL.get('taxonoicSystemID')\n",
    "                            taxLevel0 = taxSubL.get('taxonomicLevel')\n",
    "                            #taxName0 = taxSubL.get('taxonomicName')\n",
    "                            taxSubClass0 = taxSubL.get('subClassification')\n",
    "                            #taxIs0 = taxSub0.get('isITIS')\n",
    "                                                \n",
    "                            for c in range(0,len(taxSubClass0)):\n",
    "                                subKingdom =taxSubClass0[c]\n",
    "                                \n",
    "                                for d in range(0,len(subKingdom)):\n",
    "                                    infraKingdomL = subKingdom.get('subClassification')\n",
    "                                    \n",
    "                                    for e in range(0,len(infraKingdomL)):\n",
    "                                        infraKingdom = infraKingdomL[0]\n",
    "                                        phylumL = infraKingdom.get('subClassification')\n",
    "                                               \n",
    "                                        for f in range (0,len(phylumL)):\n",
    "                                            phylum = phylumL[0]\n",
    "                                            subphylumL = phylum.get('subClassification')\n",
    "                                                                     \n",
    "                                            for g in range(0,len(subphylumL)):        \n",
    "                                                subphylum = subphylumL[0]\n",
    "                                                infraphylumL = subphylum.get('subClassification')\n",
    "                                                for h in range(0,len(infraphylumL)):\n",
    "                                                    infraphylum = infraphylumL[0]\n",
    "                                                    superclassL = infraphylum.get('subClassification')\n",
    "                                                                      \n",
    "                                                    for i in range(0,len(superclassL)):\n",
    "                                                        superclass = superclassL[0]\n",
    "                                                        classL = superclass.get('subClassification')\n",
    "                 \n",
    "                                                        if classL is not None:\n",
    "                                                            for j in range(0,len(classL)): \n",
    "                                                                classD = classL[0]\n",
    "                                                                                                                  \n",
    "                                                                if classD is not None:\n",
    "                                                                    for k in range(0,len(classD)):\n",
    "                                                                        orderL = classD.get('subClassification')\n",
    "                                                                        \n",
    "                                                                        if orderL is not None:                                                            \n",
    "                                                                            for l in range(0,len(orderL)):\n",
    "                                                                                order = orderL[0]\n",
    "                                                                                familyL = order.get('subClassification')\n",
    "            \n",
    "                                                                                if familyL is not None:\n",
    "                                                                                    for m in range(0,len(familyL)):\n",
    "                                                                                        family = familyL[m]\n",
    "                                                                                        genusL = family.get('subClassification')\n",
    "\n",
    "                                                                                        if genusL is not None:\n",
    "                                                                                            for n in range(0,len(genusL)):\n",
    "                                                                                                taxx = genusL[n]\n",
    "                                                                                                tax = taxx.get('taxonomicName')\n",
    "                                                                                                if taxx.get('subClassification','none') != 'none':\n",
    "                                                                                                    sub = taxx.get('subClassification')\n",
    "                                                                                                    for s in range(0,len(sub)):\n",
    "                                                                                                        spec = sub[s]\n",
    "                                                                                                        sp = spec.get('taxonomicName')\n",
    "                                                                                                        if sp not in taxname:\n",
    "                                                                                                            taxname.append(sp)\n",
    "                                                                                                        commm = spec.get('commonName')\n",
    "                                                                                                        if commm not in comname:\n",
    "                                                                                                            comname.append(commm)\n",
    "                                                                                                else:\n",
    "                                                                                                    taxx = genusL[0]\n",
    "                                                                                                    taxa = taxx.get('taxonomicName') \n",
    "                                                                                                    if taxa not in taxname:\n",
    "                                                                                                        taxname.append(taxa) #taxname list harvested to output fields\n",
    "                                                                                                    common = taxx.get('commonName')\n",
    "                                                                                                    if common not in comname:\n",
    "                                                                                                        comname.append(common) #comname list harvested to output fields     \n",
    "                                \n",
    "                else:\n",
    "                    taxnameList = 'non-ITIS taxonomy'\n",
    "                    comnameList = 'non-ITIS taxonomy' \n",
    "\n",
    "            #formating taxonomic output:    \n",
    "            for i in range(len(taxname)):\n",
    "                taxname[i]=taxname[i].replace(\"''\",\"\")\n",
    "                \n",
    "            taxnameList = listToString(taxname)\n",
    "                \n",
    "            c2=[]#print (type(comname))\n",
    "            for c in comname:\n",
    "                #print(c)# (list(c))\n",
    "                if c != None and type(c) == list:\n",
    "                    cstr = listToString(c)\n",
    "                    cstr.rstrip(\"'\")\n",
    "                    cstr.rstrip('\"\"')          \n",
    "                    c2.append(cstr)\n",
    "            comnameList = listToString(c2)                     \n",
    "                                             \n",
    "        #RESOURCE DISTRIBUTION: get resourceDistribution metadata\n",
    "        resourceDistribution = metadata.get('resourceDistribution')\n",
    "        distlist = {} #create empty distribution list\n",
    "        #print (resourceDistribution)\n",
    "        try:\n",
    "            for d in range(0, len(resourceDistribution)): #iterate through resourceDistribution info list\n",
    "                distributor = resourceDistribution[d]\n",
    "                dist = dict(distributor)\n",
    "                dist0 = dist.get(\"distributor\")\n",
    "                dist1 = dist0[0] #dictionary keys = 'contact', 'transferOption'\n",
    "                contact = dist1.get('contact')\n",
    "                order = dist1.get('orderProcess')\n",
    "                transopt = dist1.get('transferOption')\n",
    "                distrole =contact.get('role') #harvested as distributor role to distlist\n",
    "                distparty = contact.get('party') #distrbutor contact identifiers\n",
    "                #if len(distparty) > 1:\n",
    "                    #for org in range(0,len(distparty)): \n",
    "                        #distID = distparty[0]\n",
    "                        #distributorID = distID.get('contactId') #harvest distributor ID & compare with contact master list be\n",
    "                #else:\n",
    "                distID = distparty[0]\n",
    "                distributorID = distID.get('contactId') #harvest distributor ID & compare with contact master list be\n",
    "                transopt1 = transopt[0]\n",
    "                transopt2 = transopt1.get('onlineOption')\n",
    "                transopt3 = transopt2[0]\n",
    "                onlineName = transopt3.get('name') #harvested to distlist\n",
    "                onlineUri = transopt3.get('uri') #harvested to distlist\n",
    "                distInfo =[distrole, distributorID, onlineName, onlineUri]\n",
    "                distlist[d] = distInfo\n",
    "                #print (\"distlist = \", distlist)\n",
    "                distInfoString = '; '.join(distInfo)\n",
    "    \n",
    "        except:\n",
    "            #print(title, ' has NO distribution metadata')\n",
    "            distInfoString = ' '      \n",
    "\n",
    "        #Associated product list:\n",
    "        assoclistString = 'tbd'\n",
    "\n",
    "        #Extent bounding box\n",
    "        northlat = 'empty'\n",
    "        southlat = 'empty'\n",
    "        eastlong = 'empty'\n",
    "        westlong = 'enpty'\n",
    "        geoDis = 'empty'\n",
    "        if isinstance(extent, list) == True:\n",
    "            extenlist = (extent[0])\n",
    "            #Extent description, if present.\n",
    "            if 'description' in extenlist:\n",
    "                geoDis = extenlist['description']\n",
    "            else:\n",
    "                geoDis = 'noExtentDiscription'\n",
    "            #Extent bounding box, if present.\n",
    "            if 'geographicExtent' in extenlist:\n",
    "                extenGeo = extenlist['geographicExtent']\n",
    "                extenGeo1 = extenGeo[0]\n",
    "                if 'boundingBox' in extenGeo1:\n",
    "                    extenBox = extenGeo1['boundingBox']\n",
    "                    northlat = extenBox.get('northLatitude')  #harvest for mbm national asset catalog\n",
    "                    southlat = extenBox.get('southLatitude')  #harvest for mbm national asset catalog\n",
    "                    eastlong = extenBox.get('eastLongitude')  #harvest for mbm national asset catalog\n",
    "                    westlong = extenBox.get('westLongitude')  #harvest for mbm national asset catalog      \n",
    "        else:\n",
    "            northlat = 'na'\n",
    "            southlat = 'na'\n",
    "            eastlong = 'na'\n",
    "            westlong = 'na'\n",
    "            geoDis = 'none'\n",
    "\n",
    "       #POINTS of CONTACT\n",
    "        #read Master Contact JSON metadata file into dataframe\n",
    "        contactmetadata = pd.read_json(contact_md)\n",
    "        contactmd1 = dict(contactmetadata)\n",
    "        contactmd2 = contactmd1.get('data')\n",
    "        \n",
    "        POC = collections.defaultdict(list) # create empty dictionary for contacts\n",
    "        POCvalues = []\n",
    "        count = 0\n",
    "\n",
    "        #iterate through master contact metadata\n",
    "        for k in contactmd2:\n",
    "            contactmd3 = contactmd2[count]\n",
    "            contactmd4 = contactmd3.get('attributes')\n",
    "            contactmd5 = contactmd4.get('json')\n",
    "            if contactmd5 is not None:\n",
    "                contactmd6 = json.loads(contactmd5)\n",
    "                contactmd7 = dict(contactmd6)\n",
    "                contactIDmd = contactmd7.get('contactId') #harvest id#\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            for id in distlist:\n",
    "                if distlist[id][1] == contactIDmd:\n",
    "                    contactisOrganizationmd = contactmd7.get('isOrganization')\n",
    "                    contactName = contactmd7.get('name') #havest as distributor name to fields\n",
    "                    contactMemberOf = contactmd7.get('memberOfOrganization')\n",
    "                    contactemail = contactmd7.get('electronicMailAdddress')\n",
    "                    contactType = contactmd7.get('contactType')\n",
    "                    distlist[id][1] = contactName \n",
    "\n",
    "            # iterate through contacts from metadata\n",
    "            for j in pointOfContact:\n",
    "                party = j.get('party')\n",
    "                for p in range(0, len(party)):\n",
    "                    partyContact = party[p]\n",
    "                    partyContactID = partyContact.get('contactId') #id to compare in master contact list\n",
    "                    role = j.get('role')\n",
    "    \n",
    "                    #compare master list contact ID with metadata contact ID\n",
    "                    if contactIDmd == partyContactID:\n",
    "                        contactisOrganizationmd = contactmd7.get('isOrganization')\n",
    "                        contactName = contactmd7.get('name')\n",
    "                        contactMemberOf = contactmd7.get('memberOfOrganization')\n",
    "                        contactemail = contactmd7.get('electronicMailAdddress')\n",
    "                        contactType = contactmd7.get('contactType')\n",
    "                        POC[role].append(contactName)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            owner = listToString(POC['owner'])\n",
    "            PointOC = listToString(POC['pointOfContact'])\n",
    "            princ = listToString(POC['principalInvestigator'])\n",
    "            custodian = listToString(POC['custodian'])\n",
    "            admin = listToString(POC['administrator'])\n",
    "            originator = listToString(POC['originator'])\n",
    "            contributor = listToString(POC['contributor'])\n",
    "            #distlistString = '; '.join(distInfo) \n",
    "\n",
    "\n",
    "       #Write vales to CSV\n",
    "        fields = [ID, ids, typee, title, altTitle, typeename, purpose, abstract, shortAbstract, \n",
    "                  PointOC, owner, princ, custodian, admin, originator, contributor, startDate, endDate, lastUpdate, status, \n",
    "                  metaIdentifier, metadataStatus, keywords, taxnameList, comnameList, distInfoString, assoclistString,\n",
    "                  northlat, southlat, eastlong, westlong, geoDis]\n",
    "        \n",
    "        #write files to csv\n",
    "        with open (csvname, 'a', newline = '') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(fields) \n",
    "            #print(\"CSV created./n\",\"Number of contacts in master list = \", len(contactmd2))     \n",
    "\n",
    "\n",
    "        \n",
    "        #Extent to geodataframe if True\n",
    "        if geo == True:  #only gather extents from projects?\n",
    "            if 'geographicExtent' not in extenlist:\n",
    "                print ('metadata has NO geographic extent.')\n",
    "                continue\n",
    "            else:\n",
    "                extenGeo = extenlist['geographicExtent']\n",
    "                extenGeo1 = extenGeo[0]\n",
    "                if 'geographicElement' not in extenGeo1:  \n",
    "                    print ('metadata has NO Geometry.')\n",
    "                    continue\n",
    "                else:\n",
    "                    extenGeoElement = extenGeo1['geographicElement'] #type = list\n",
    "                    geoInput =[] #empty list for geoinput to geodataframe\n",
    "                    poly = gpd.GeoDataFrame(columns = ['ID', 'ids' 'name','geometry', 'type', 'title', 'altTitle', 'typename', \n",
    "                                                       'purpose', 'abstract', 'shortAb', 'PointOC', 'trustee', 'PI', \n",
    "                                                       'custodian', 'admin', 'origin', 'contrib', 'startDate', 'endDate', 'lastUpdat',\n",
    "                                                       'status', 'metaIdent', 'metaStatus', 'keywords', 'taxname', 'comname',\n",
    "                                                       'distib', 'assoc']) #gEid?\n",
    "                    for ex in range(0, len(extenGeoElement)): #need id, name, descripiton, geometry\n",
    "                        gElement = extenGeoElement[ex]  #=dict_keys(['type', 'id', 'geometry', 'properties']) or ['type', 'features']\n",
    "                        if gElement.get('type') == \"FeatureCollection\":\n",
    "                            extrastep = gElement.get('features')\n",
    "                            nextstep = extrastep[0] #=dict_keys(['type', 'id', 'geometry', 'properties'])\n",
    "                            gtype = nextstep.get('type') #Feature\n",
    "                            gEid = nextstep.get('id') #harvest as GeoID to fields\n",
    "                            gEgeometry = nextstep.get('geometry') #type=dict_keys(['type', 'coordinates'])\n",
    "                            ggtype = gEgeometry.get('type')\n",
    "                            gcoordinates = gEgeometry.get('coordinates')#list\n",
    "                            #print (gcoordinates)\n",
    "                            gEcoordinates = gcoordinates[0] #list length = 1\n",
    "                            \n",
    "                            if len(gEcoordinates) == 1:\n",
    "                                gEcoordinates = gEcoordinates[0]\n",
    "                        \n",
    "                            #poly_coord = Polygon(gEcoordinates)\n",
    "                            gEproperties = nextstep.get('properties')\n",
    "                            gname = gEproperties.get ('name', 'NotNamed') #harvested to geodataframe\n",
    "                            propertyDesc = gEproperties.get('description', 'NotDescribed')\n",
    "                        \n",
    "                            if ggtype == 'Polygon':\n",
    "                                #gcoordinates = gEgeometry.get('coordinates')#list\n",
    "                                #gEcoordinates = gcoordinates[0] #list\n",
    "                                poly_coord = Polygon(gEcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'ids': ids, 'name':gname, 'geometry':poly_coord, 'type':typee, 'title':title, \n",
    "                                    'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdat':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #creating dict of geoattrit of geoattribute \n",
    "                                geoInput.append(geoattributes)\n",
    "                            elif ggtype == 'Point':\n",
    "                                ptcoordinates = gEgeometry.get('coordinates')\n",
    "                                pt_coord = Point(ptcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'name':gname, 'geometry':pt_coord, 'type':typee, 'title':title, \n",
    "                                   'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdate':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoattributesgeoattributes = {'id':gEid, 'name':gname, 'geometry':pt_coord} #creating dict of geoattributes\n",
    "                                geoInput.append(geoattributes)\n",
    "                            elif ggtype == 'MultiPolygon':\n",
    "                                print ('this is multipolygon')\n",
    "                                mpoly_coord = MultiPolygon(gEcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'ids': ids, 'name':gname, 'geometry':mpoly_coord, 'type':typee, 'title':title, \n",
    "                                    'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdat':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoatttribut                        \n",
    "                                geoInput.append(geoattributes)\n",
    "                            else:\n",
    "                                continue\n",
    "                            \n",
    "                        elif gElement.get('type') == \"Feature\":\n",
    "                            gEtype = gElement.get('type') #dict_keys(['type', 'id', 'geometry', 'properties'])\n",
    "                            gEid = gElement.get('id') #harvest as GeoID to fields\n",
    "                            gEgeometry = gElement.get('geometry') #type=dict_keys(['type', 'coordinates'])\n",
    "                            try:\n",
    "                                gEproperties = gElement.get('properties')\n",
    "                                gname = gEproperties.get ('name', 'NotNamed') #harvested to geodataframe\n",
    "                                #propertyDesc = gEproperties.get('description')\n",
    "                            except: \n",
    "                                gname = 'NotDefined'\n",
    "                            gtype = gEgeometry.get('type') #indicates geometry type: Polygon, Point, line\n",
    "                            if gtype == 'Polygon':\n",
    "                                gcoordinates = gEgeometry.get('coordinates')#list\n",
    "                                gEcoordinates = gcoordinates[0] #list\n",
    "                                poly_coord = Polygon(gEcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'ids': ids, 'name':gname, 'geometry':poly_coord, 'type':typee, 'title':title, \n",
    "                                   'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdat':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoattributes\n",
    "                                geoInput.append(geoattributes)\n",
    "                            elif gtype == 'Point':\n",
    "                                ptcoordinates = gEgeometry.get('coordinates')\n",
    "                                pt_coord = Point(ptcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'ids': ids, 'name':gname, 'geometry':pt_coord, 'type':typee, 'title':title, \n",
    "                                   'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdat':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoattributes\n",
    "                                geoInput.append(geoattributes)\n",
    "                            elif gtype == 'LineString':\n",
    "                                ptcoordinates = gEgeometry.get('coordinates')\n",
    "                                ln_coord = LineString(ptcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'name':gname, 'geometry':ln_coord, 'type':typee, 'title':title, \n",
    "                                   'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdate':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoattributesgeoattributes = {'id':gEid, 'name':gname, 'geometry':pt_coord} #creating dict of geoattributes\n",
    "                                geoInput.append(geoattributes)\n",
    "                            elif gtype == 'MultiPolygon':\n",
    "                                gcoordinates = gEgeometry.get('coordinates')#list\n",
    "                                gEcoordinates = gcoordinates[0] #list\n",
    "                                mpoly_coord = MultiPolygon(gEcoordinates)\n",
    "                                geoattributes = {'id':gEid, 'ids': ids, 'name':gname, 'geometry':mpoly_coord, 'type':typee, 'title':title, \n",
    "                                    'altTitle':altTitle, 'typename':typeename, 'purpose':purpose, 'abstract':abstract, 'shortAb':shortAbstract, \n",
    "                                    'PointOC':PointOC, 'trustee':owner, 'PI':princ, 'custodian':custodian, 'admin':admin,\n",
    "                                    'origin':originator, 'contrib':contributor, 'startDate':startDate, \n",
    "                                    'endDate':endDate, 'lastUpdat':lastUpdate, 'status':status, \n",
    "                                    'metaIdent':metaIdentifier, 'metaStatus':metadataStatus, 'keywords':keywords, 'taxname':taxnameList,\n",
    "                                    'comname':comnameList, 'distrib':distInfoString, 'assoc':assoclistString} #gEid?} #creating dict of geoattributes\n",
    "                                geoInput.append(geoattributes)\n",
    "                            else:\n",
    "                                continue    \n",
    "            \n",
    "                    poly = gpd.GeoDataFrame(geoInput, geometry = 'geometry', crs = \"EPSG:4326\")  #crs = lat, long designation \n",
    "                    polyname = str(workspace + title[0:12] +'.shp') #generate name for shapefile \n",
    "        \n",
    "                            #if geography is desired, then merge metadata with extent and output shapefile\n",
    "                            #if outShape == True:\n",
    "                            #Create shapefile from csv with geographic info\n",
    "                            #metadf = pd.read_csv(csvname, encoding = 'cp1252') #read completed csv into dataframe\n",
    "            \n",
    "                            #Subset for projects only\n",
    "                            #projectOnly = pd.DataFrame(metadf.loc[metadf['typee'] == 'project'])\n",
    "            \n",
    "                            #merge geodataframe with metadata dataframe\n",
    "                            #dfmerge = pd.merge(poly, projectOnly, how='cross')#,left_on='id',right_on='GeoID')\n",
    "            \n",
    "                    #write shapefile\n",
    "                    poly.to_file(polyname, encoding = 'utf-8')#, driver = 'ESRI Shapefile', schema = {\"geometry\": \"Polygon\", \"properties\":{\"id\":\"int\"}})\n",
    "                    print(\"Geometry found.\") \n",
    "        else:\n",
    "            continue\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Migratory Birds Management RDR folder for mdeditor files to extract metadata\n",
    "#Count number of preserved mdEditor records\n",
    "import os\n",
    "RDR = '\\\\\\\\ifw7ro-file.fws.doi.net\\\\datamgt\\\\mbm'\n",
    "MBMmetadataNo = 0\n",
    "program = \"Migratory Bird Manangement\"\n",
    "\n",
    "# Pathway to the contacts file you want to use to check against existing vs. new contacts; i.e., master AK contacts file\\n\",\n",
    "contact_md = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\AK_contacts_profiles\\\\AK-contacts-mdeditor-20250122-150150.json'\n",
    "\n",
    "# Pathway to csv file where to write metaata\n",
    "csvname = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\CatalogCSV\\\\catalogCSVPhase220250404.csv'\n",
    "\n",
    "workspace = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\CatalogCSV\\\\MBMExtentTest\\\\'\n",
    "\n",
    "#loop through RDR folder structure and find mdeditor json files that is NOT in incoming folder\n",
    "for root, dirs, files in os.walk(RDR,topdown=True):\n",
    "    #print (\"root=\", root, \"  dirs=\", dirs, \"  file=\", files)\n",
    "    for name in files:\n",
    "        if 'incoming' not in root and 'archive' not in root and 'mdeditor' in name and 'init' not in name and name.endswith('.json'):\n",
    "            jfile = os.path.join(root,name)\n",
    "            mdEditor_read(jfile, contact_md, csvname, workspace, resourcetype ='project', geo=True)\n",
    "            MBMmetadataNo += 1\n",
    "            print (jfile, \" Done.\")\n",
    "print (\"Number of MBM completed mdeditor records in RDR = \", MBMmetadataNo) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "workspace = \"C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\CatalogCSV\\\\MBMExtentTest\\\\\"\n",
    "\n",
    "def merge_polygon_shapefiles(directory, output='merged.shp'):\n",
    "    #merge all shapefiles in a directory intos a singe shapefile.\n",
    "    shapefiles = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.shp'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            geo = gpd.read_file(filepath)\n",
    "            geo = geo[geo['geometry'].geom_type.isin(['Polygon'])] \n",
    "            shapefiles.append(geo)\n",
    "              \n",
    "\n",
    "    if not shapefiles:\n",
    "        raise ValueError (\"No shapefiles found in the directory.\")\n",
    "    \n",
    "    merged_geo = pd. concat(shapefiles, ignore_index=True)\n",
    "    merged_geo.to_file(output)\n",
    "    print(f\"Successfully merged shapefiles to {output}\")\n",
    "    return\n",
    "\n",
    "merge_polygon_shapefiles(workspace, output= workspace + 'merged.shp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
