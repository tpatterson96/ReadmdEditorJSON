{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc46b33",
   "metadata": {},
   "source": [
    "This code is a modification of the RDRstats script.  It also is appiled to the Alaska Regional Data Repository content.  It is designed to pull content for Dec2025-Jan2026 leadership informational request.\n",
    "including the following fields: program, region, office, Current Point of Contact, Project Name and Description; Prinary Decision Category and link (not available in the metadata currently); data release date, exclusions, repository and comments; artifacts included presence of fieldnotes, Data Management plan, raw data files, final data, scripts/code, methoods/protocols, reports/publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "def find_program(x):\n",
    "    if 'mbm' in x:\n",
    "        y = 'mbm'\n",
    "    elif 'fes' in x:\n",
    "        y = 'fes'\n",
    "    elif 'nwrs' in x:\n",
    "        y = 'nwrs'\n",
    "    elif 'sa' in x:\n",
    "        y = 'sa'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "#define functions\n",
    "def find_team(x):\n",
    "    if 'mbmjv' in x:\n",
    "        y = 'SeaduckJV'\n",
    "    elif 'mbmlb' in x:\n",
    "        y = 'Landbirds'\n",
    "    elif 'mbmra' in x:\n",
    "        y = 'Raptors'\n",
    "    elif 'mbmsb' in x:\n",
    "        y = 'Seabirds'\n",
    "    elif 'mbmsh' in x:\n",
    "        y = 'Shorebirds'\n",
    "    elif 'mbmss' in x:\n",
    "        y = 'Science Support'\n",
    "    elif 'mbmwa' in x: \n",
    "        y = 'Waterfowl'\n",
    "    elif 'mbmambcc' in x:\n",
    "        y = 'AMBCC'\n",
    "    elif 'fesecs' in x:\n",
    "        y = 'Ecological Services Reional Office'\n",
    "    elif 'fescgl' in x:\n",
    "        y = 'Conservation Genetics Lab'\n",
    "    elif 'fessaf' in x:\n",
    "        y = 'Southern Alaskan FWCO Fisheries'\n",
    "    elif 'fessae' in x:\n",
    "        y = 'Southern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesnaf' in x:\n",
    "        y = 'Northern Alaskan FWCO Fisheries'\n",
    "    elif 'fesnae' in x:\n",
    "        y = 'Northern Alaskan FWCO Ecological Services'\n",
    "    elif 'fesmmm' in x:\n",
    "        y = 'Marine Mammals Management'\n",
    "    elif 'fesesc' in x: \n",
    "        y = 'Regional Ecological Services'\n",
    "    elif 'fesisp' in x:\n",
    "        y = 'Invasive Species Program'\n",
    "    elif 'feshrp' in x:\n",
    "        y = 'Habitat Restoration and Partnerships'\n",
    "    else:\n",
    "        y = 'none'\n",
    "    return y\n",
    "\n",
    "def removeComma(string): #define remove comma function\n",
    "    return string.replace(\",\",\"; \")\n",
    "    \n",
    "def listToString(s): #define converting list to a string format\n",
    "    str1 = \"; \"\n",
    "    return (str1.join(s))\n",
    "    \n",
    "def def_value():\n",
    "    return \"none\"\n",
    "\n",
    "\n",
    "def get_folder_size(path): #Calculates the total size of a folder and its contents in bytes.\n",
    "    total_size = 0\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file():\n",
    "                total_size += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total_size += get_folder_size(entry.path)\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing path {path}: {e}\")\n",
    "        return 0\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metavalues(m, contact_md):\n",
    "    import collections\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    \n",
    "    def removeComma(string): #define remove comma function\n",
    "        return string.replace(\",\",\"; \")\n",
    "    \n",
    "    def listToString(s): #define converting list to a string format\n",
    "        str1 = \"; \"\n",
    "        return (str1.join(s))\n",
    "    \n",
    "    #set varibles to defaults \n",
    "    records = \"noMetadata\"\n",
    "    title = \"noMetadata\"\n",
    "    status = \"noMetadata\"\n",
    "    abstract = \"noMetadata\"\n",
    "    metadataStatus = \"noMetadata\"\n",
    "    startDate = 1900\n",
    "    endDate = 1900\n",
    "    DOI = \"none\"\n",
    "    RDR = \"none\"\n",
    "    dateType = \"none\"\n",
    "    lastUpdate = 1900\n",
    "    SB = 0\n",
    "    projectOnline = 0\n",
    "    productsOnline = 0\n",
    "    dictionary = 0\n",
    "    PointOC = \"none\"\n",
    "    owner = \"none\"\n",
    "    admin = \"none\"\n",
    "    url = \"none\"\n",
    "    code = 0\n",
    "    pubs = 0\n",
    "    proto = 0\n",
    "    typeDic = defaultdict(int)  #empty default dictionary to track metadata record types\n",
    "    ids = []\n",
    "    \n",
    "    df = pd.read_json(m)  #read JSON metadata files into dataframe\n",
    "    if len(df.get('data')) == 0 :\n",
    "        print (\"cannot read 'data'\")\n",
    "    else:\n",
    "        values = df.get('data')  #assigns metadata to values\n",
    "        for e in range(0, len(values)):  #json file may have multiple metadata records\n",
    "            element = values[e]  #assign list value e containing the metadata #keys= id, attributes, type\n",
    "            attribute = element.get('attributes')  #keys= profile, json, data-updated\n",
    "            typpe = element.get('type')   #get metadata type\n",
    "            typeDic[typpe] += 1\n",
    "            if typpe != 'records':  #skip if metadata is not a record and is a data dictionary, setting, schemas, custom-profiles...   \n",
    "                continue  #go to next record\n",
    "            jsondata = attribute.get('json')  #create'json' data value\n",
    "            #convert string to dictionary\n",
    "            jsondatadict = json.loads(jsondata)  #3 keys = schema, metadata, mdDictionary\n",
    "            metadata = jsondatadict.get('metadata')  #4 keys = metadataInfo, resourceInfo, associatedResource, resourceDistribution\\n\",\n",
    "            mdDictionary = jsondatadict.get('mdDictionary')\n",
    "            #get metadata key entries\n",
    "            resourceInfo = metadata.get('resourceInfo')        \n",
    "            #resourceInfo = 12 keys: 'resourceType', 'citation', 'pointOfContact', 'abstract', 'shortAbstract', 'status', \\n\",\n",
    "            #...'defaultResourceLocale', 'extent', 'keyword', 'purpose', 'taxonomy', 'timePeriod'\\n\",\n",
    "            resourceType = resourceInfo.get('resourceType')\n",
    "            #parse resource type info\n",
    "            typelist = resourceType[0]\n",
    "            typee = typelist.get('type')\n",
    "            #print ('typee is ', typee)\n",
    "            if typee == 'software':\n",
    "                code += 1\n",
    "            if typee == 'publication' or typee == 'report':\n",
    "                pubs += 1\n",
    "\n",
    "            typeDic[typee] += 1 # count resource type ie project, tabular dataset, dictionary, etc.\n",
    "            typeename = typelist.get('name')\n",
    "            if typeename != None: \n",
    "                typeename = removeComma(typelist.get('name'))  #harvest\n",
    "            citation = resourceInfo.get('citation')\n",
    "            title = removeComma(citation.get('title')) \n",
    "            if 'protocol' in title or 'procedure' in title: #count protocol documents\n",
    "                proto += 1 \n",
    "            pointOfContact = resourceInfo.get('pointOfContact') #harvested\n",
    "            #gather identifiers to determine repository status\n",
    "            #pull citation identifiers\n",
    "            if 'identifier' in citation:\n",
    "                identify = citation.get('identifier')\n",
    "                for fier in identify:\n",
    "                    #print (fier)\n",
    "                    try:\n",
    "                        ns = fier.get('namespace')\n",
    "                        i = fier.get('identifier')\n",
    "                        nsi = str(ns +': '+i)\n",
    "                        if ns == 'Alaska Regional Data Repository':\n",
    "                            RDR = i  #Harvest\n",
    "                        if ns == 'ServCat':\n",
    "                            if typee == 'project':\n",
    "                                url = str('https://iris.fws.gov/APPS/ServCat/Reference/Profile/'+ i) #Harvest\n",
    "                                projectOnline =+ 1\n",
    "                        if ns == 'gov.sciencebase.catalog':\n",
    "                            if typee == 'project':\n",
    "                                url = str('https://www.sciencebase.gov/catalog/item/'+ i) #Harvest\n",
    "                                projectOnline =+ 1\n",
    "                        ids.append(nsi)  #Harvest\n",
    "                    except:\n",
    "                        continue\n",
    "            if 'gov.sciencebase.catalog' in listToString(ids):\n",
    "                SB += 1\n",
    "            if 'ServCat' in listToString(ids):\n",
    "                SB += 1\n",
    "            \n",
    "            \n",
    "            #Pull metadata from project metadata only\n",
    "            if typee != 'project':\n",
    "                continue\n",
    "            #for project metadata, do following:    \n",
    "            metadataInfo = metadata.get('metadataInfo') #6 Keys = metadataIdentifier, metadataContact, defaultMetadataLocale, metadataDate, parentMetadata, metadataStatus\n",
    "            metadataDate = metadataInfo.get('metadataDate')\n",
    "            #parentMetadata = metadataInfo.get('parentMetadata')\n",
    "            metadataStatus = metadataInfo.get('metadataStatus')  #Harvested\n",
    "            abstract = removeComma(resourceInfo.get('abstract'))  #harvested\n",
    "            title = removeComma(citation.get('title'))  #harvested\n",
    "            responsibleParty = citation.get('responsibleParty')\n",
    "            statusList = resourceInfo.get('status')\n",
    "            status = statusList[0]  #harvest\n",
    "            #get last update date\n",
    "            try:\n",
    "                for d in range(1, len(metadataDate)):\n",
    "                    metadate = metadataDate[d]\n",
    "                    if metadate.get('dateType') == \"lastUpdate\":\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]\n",
    "                        #dateType = 'last updated'\n",
    "                    else: \n",
    "                        #dateType = metadate.get('dateType')\n",
    "                        lastUpdate = (metadate.get('date')).split('T')[0]                   \n",
    "            except:\n",
    "                lastUpdate = \"None\"\n",
    "                #dateType = \"None\"\n",
    "            #Get and format startDate and endDate\n",
    "            timePeriod = resourceInfo.get('timePeriod') \n",
    "            try:\n",
    "                startDate = (timePeriod.get('startDateTime','None')).split('T')[0]\n",
    "                end = timePeriod.get('endDateTime', 'None')\n",
    "                if end == None:\n",
    "                    endDate = 'onGoing'\n",
    "                else:\n",
    "                    endDate = end.split('T')[0]\n",
    "            except:\n",
    "                startDate = 'None'\n",
    "                endDate = 'None'\n",
    "\n",
    "\n",
    "        #POINTS of CONTACT\n",
    "        #read Master Contact JSON metadata file into dataframe\n",
    "        contactmetadata = pd.read_json(contact_md)\n",
    "        contactmd1 = dict(contactmetadata)\n",
    "        contactmd2 = contactmd1.get('data')\n",
    "        POC = collections.defaultdict(list) # create empty dictionary for contacts\n",
    "        POCvalues = []\n",
    "        count = 0\n",
    "        #iterate through master contact metadata\n",
    "        for k in contactmd2:\n",
    "            contactmd3 = contactmd2[count]\n",
    "            contactmd4 = contactmd3.get('attributes')\n",
    "            contactmd5 = contactmd4.get('json')\n",
    "            if contactmd5 is not None:\n",
    "                contactmd6 = json.loads(contactmd5)\n",
    "                contactmd7 = dict(contactmd6)\n",
    "                contactIDmd = contactmd7.get('contactId') #harvest id#\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "            # iterate through contacts from metadata\n",
    "            for j in pointOfContact:\n",
    "                party = j.get('party')\n",
    "                for p in range(0, len(party)):\n",
    "                    partyContact = party[p]\n",
    "                    partyContactID = partyContact.get('contactId') #id to compare in master contact list\n",
    "                    role = j.get('role')\n",
    "    \n",
    "                    #compare master list contact ID with metadata contact ID\n",
    "                    if contactIDmd == partyContactID:\n",
    "                        contactName = contactmd7.get('name')\n",
    "                        POC[role].append(contactName)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "        productsOnline = SB - projectOnline\n",
    "        owner = listToString(POC['owner'])\n",
    "        PointOC = listToString(POC['pointOfContact'])\n",
    "        admin = listToString(POC['administrator'])\n",
    "        dictionary = typeDic.get('dictionaries', 0)\n",
    "        records = str(typeDic).removeprefix(str(\"defaultdict(<class 'int'>, {\")).replace(\"})\",'')\n",
    "    \n",
    "    return [records, title, status, abstract, metadataStatus, startDate, endDate, RDR, lastUpdate, PointOC, owner, admin, url, projectOnline, productsOnline, dictionary, code, pubs, proto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429944c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ME for mbm! (and fes need to change RDR location)  \n",
    "\n",
    "#import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "# Pathway to directory of interest\n",
    "RDR = '\\\\\\\\ifw7ro-file.fws.doi.net\\\\datamgt\\\\mbm\\\\'  #change for mbb or fes\n",
    "\n",
    "# Pathway to the contacts file you want to use to check against existing vs. new contacts; i.e., master AK contacts file\\n\",\n",
    "contact_md = 'C:\\\\Users\\\\tpatterson\\\\OneDrive - DOI\\\\Documents\\\\DM_Metadatafiles\\\\AK_contacts_profiles\\\\AK-contacts-mdeditor-20250818-205544.json''\n",
    "\n",
    "#create dataframe to hold stats\n",
    "stats = pd.DataFrame(columns=['RDR_folder', 'program','subprogram', 'records', 'title', 'projectStatus', 'abstract', 'metadataStatus', 'startDate', 'endDate', \n",
    "                                  'ID', 'lastDate', 'pointOfContact', 'dataTrustee', 'dataAdmin', 'url', 'projectOnline', \n",
    "                                  'productsOnline', 'dictionary', 'finalData', 'rawData', 'dataPresent', 'DMP', 'Script',  'Reports/Pubs', 'Protocols'])                         \n",
    "     \n",
    "#walk project folders\n",
    "folders = os.listdir(RDR) #list of RDR folders\n",
    "for f in folders:\n",
    "    program = find_program(f[0:3]) # find program name\n",
    "    if f.find('mbm', 0, 3) != -1:  # read MBM or FES project folders only\n",
    "        team = find_team(f[0:5])    # change to :5 for MBM and :6 for Fes\n",
    "        #set defaults\n",
    "        DMP = 0\n",
    "        finalByte = 0\n",
    "        rawByte = 0\n",
    "        dataPresent = 0\n",
    "        script = 'Not Applicable'\n",
    "        #readmdJSON = ['records', 'title', 'status','abstract', 'metadataStatus', 'startDate', 'endDate', 'RDR', 'lastUpdate', 'PointOC', 'owner', 'admin', 'url', 'projectOnline', 'productsOnline', 'dictionary', 'scripts', 'publications', 'protocols'])\n",
    "        metaread = ['noMetadata', 'noMetadata', 'noMetadata', 'noMetadata', 'noMetadata', 1900, 1900, 'noMetadata', 1900, 'noMetadata', 'noMetadata', 'noMetadata', 'noURL', 0, 0, 0, 0, 0, 0] #set defaults\n",
    "        f2 = os.path.join(RDR, f)\n",
    "        print ('Opening folder: ', f2)\n",
    "        \n",
    "        for root, dirs, files in os.walk(str(f2), topdown=True):\n",
    "            #print (root)\n",
    "            if root.endswith('final_data') and 'incoming' not in root: # if data folder, find size\n",
    "                finalByte = get_folder_size(root)\n",
    "                if finalByte > 0:\n",
    "                    dataPresent = 1\n",
    "                else:\n",
    "                    dataPresent = 0\n",
    "            if root.endswith('data\\\\raw_data') and 'incoming' not in root:\n",
    "                rawByte = get_folder_size(root)\n",
    "                if rawByte > 0:\n",
    "                    dataPresent = 1\n",
    "            \n",
    "            for name in files:\n",
    "                 #check for DMP in folder\n",
    "                if name.startswith(\"AK_DMP\", 0, 6) and name.endswith(('.docx', 'docm')):\n",
    "                    DMP += 1\n",
    "                #if name.endswith(('.docx', 'docm')): #check for other documents\n",
    "                    #print (f'Project folder {f2} \\n contains document {name} \\n')\n",
    "                #get project metadata info from mdEditor JSON file\n",
    "                if 'archive' not in root and 'incoming' not in root and '-init-' not in name and 'mdeditor' in name and 'mdJSON' not in root and 'metadata' in root and name.endswith('.json'):\n",
    "                    jfile = os.path.join(root,name)\n",
    "                    metaread = get_metavalues(jfile, contact_md)\n",
    "                    print ('Reading: ', jfile)\n",
    "                else:\n",
    "                    continue\n",
    "               \n",
    "        #write values to the dataframe\n",
    "        line =[f, program, team, metaread[0], metaread[1], metaread[2], metaread[3], metaread[4], metaread[5], metaread[6], metaread[7], metaread[8], metaread[9], metaread[10], metaread[11], metaread[12], metaread[13], metaread[14], metaread[15], metaread[16], metaread[17], metaread[18],finalByte/1000000, rawByte/1000000, dataPresent, DMP]    \n",
    "        stats.loc[len(stats.index)] = line\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
